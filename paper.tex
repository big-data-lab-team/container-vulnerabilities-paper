% GigaScience template
\documentclass[a4paper,num-refs]{oup-contemporary}

\journal{gigascience}


%%%% Packages %%%%
\usepackage{siunitx}
\usepackage{algpseudocode} % Algorithmic environment
\usepackage{xspace}
\usepackage{csvsimple}
\usepackage{minted} % Used for JSON highlighting
\usepackage{datatool}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{array}
\usepackage{algorithm}
\usepackage{caption}
\usepackage[justification=centering]{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{adjustbox}
\usepackage{makecell}
\usepackage{titlesec}
\usepackage[flushleft]{threeparttable}

%%%% Commands %%%%
\newcommand{\todo}[1]{\color{red}\textbf{TODO:}#1\color{black}}
\newcommand{\change}[2]{\color{cyan}Changes: #1\color{black}}
\newcommand{\reprozip}[0]{ReproZip}
\newcommand{\rom}[1]{\lowercase\expandafter{\romannumeral #1\relax}}
\newcommand{\tristan}[1]{\color{blue}From Tristan: #1\color{black}}

\renewcommand{\labelitemi}{$\textendash$}
\title{Vulnerability Analysis of Container Images in Neuroimaging}
  
\begin{document}

\author[1]{Bhupinder Kaur}
\author[1]{Aiman Hanna}
\author[1]{Tristan Glatard}

\affil[1]{Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada}

\maketitle

\begin{abstract}

Today, containers, which provide operating system level virtualization, are
popular. Correspondingly, they are widely used for scientific data analyses on 
High Performance Computing (HPC) clusters. However, the security of containers
still remains the concerning issue. Here, we focus on the security of container
images in particular. Container images are often built for the entire
duration of an analysis, so scientific researchers do not prefer to update
them. Consequently, their chances of containing vulnerabilities increases.  
In this study, we analyze vulnerabilities in container images used in 
HPC clusters.
We conduct two different
experiments, image update and image shrinking, to report the effect 
on the number of vulnerabilities.

\end{abstract}

\begin{keywords}
Containers; Docker; Singularity; Security Vulnerabilities; Neuroimaging.
\end{keywords}


\section{Introduction}

% Containers are popular on HPC, in particular Singularity
Software containers have emerged has an efficient solution to deploy
scientific data analyses on High Performance Computing (HPC) clusters, due
to their portability, ease of use, and limited overhead. The
Singularity~\cite{kurtzer2017singularity} framework is often preferred to
Docker\footnote{\url{http://docker.com}} on HPC clusters, due to its
secure handling of multi-user environments, and its convenient support for
Docker images. Singularity is now available in dozens of HPC
clusters around the globe, and used routinely for Big Data analyses.

% Containers are meant to isolate applications from the host, but security remains an issue
Using core features of the Linux kernel such as namespaces, control groups
and chroot, containers isolate processes from the
host computer,  
and control the memory, CPU, network and file-system resources assigned to
them. However, containers still share the kernel, mounted file systems and
some devices with the host, which raises potential security issues. In
particular, privilege escalation, denial of service and information leak
are always plausible~\cite{gantikow2016providing}. Therefore, security remains 
an important concern when deploying containers~\cite{bettini2015vulnerability}.

% Container images, our study
This study is a vulnerability analysis of container images used in HPC
clusters. Container images contain complete operating-system distributions,
including the data analysis software and its required dependencies.
Images are rarely updated, as they are often built once
for the entire duration of an analysis, to avoid results perturbations
coming from software updates~\cite{gronenschild2012effects, glatard2015reproducibility}. Images also
commonly include more dependencies than required by a specific analysis, to 
enable reusability across experiments.

Our research questions are the following:

\textit{RQ1: What is the current amount of known vulnerabilities in
container images deployed on HPC clusters?} Vulnerabilities are possible
attack vectors that may seriously compromise the security of HPC clusters
and the integrity of user data. We report vulnerability analyses produced
by four popular image scanning tools, Anchore, Vuls, Clair-scanner and Stools.

\textit{RQ2: Can the amount of vulnerabilities be reduced by updating the images?}  
For many reasons related to reproducibility and the life-cycle of research
projects, container images deployed on HPC clusters often include outdated
software. We report on the effect of software updates on the vulnerability
analysis of RQ1.

\textit{RQ3: Can the amount of vulnerabilities be reduced by shrinking the images?} 
Container images often include more software packages than required for a
typical analysis. We report on the impact of this additional software on
the presence of vulnerabilities.

We answer these questions taking the particular example of neuroimaging, a
domain that has entered the Big Data era as many other
ones~\cite{van2014human}. We focus on the analysis of container images
present in BIDS apps~\cite{gorgolewski2017bids} and Boutiques~\cite{glatard2018boutiques}, two containerized
application frameworks commonly used in neuroimaging. 


The next section describes the materials and tools used in the experiments,
including image scanners and container images. We then describe our image
update and shrinking methodology to reduce vulnerabilities. Results review
the detected vulnerabilities in container images, explain observed
discrepancies between scanners, and report on the efficiency of image
update and size reduction. As a conclusion, we provide a set of image
creation guidelines for a secure deployment on HPC clusters.

%This paper is organized as follows: in the next section, we provide a description
%of materials and methods which summarize our experiments. We also explain different
%image scanners used to report
%vulnerabilities in container images. The next section of this paper provides the results, where we
%present a number of existing vulnerabilities in the container images
%used for data analysis on shared HPC clusters. We then proceed in the following section with 
%discussion and analysis of these results, where we provide more insight into the problems that 
%we faced while conducting these experiments. We also propose some
%particular rules that can be followed to secure container images. Finally, conclusions are drawn
%in the last section of the paper.

\todo{Add related work on vulnerability scanning}

\section{Materials and Tools}

Since the aim of this research work is to detect security vulnerabilities
in container images and attempt to examine the effect of different
manipulation of these images, it is needed to have a representative set
images. Additionally, for the purpose of detecting vulnerabilities,
utilization of image scanners is required. We utilize container
images from two popular application frameworks, as well as
four of the main image scanners.

\subsection{Container Images}

We scan a total of 44 container images taken from two containerization frameworks
used in neuroscience: BIDS
apps~\cite{gorgolewski2017bids} and Boutiques~\cite{glatard2018boutiques}.
Out of these 44 images, 26 were obtained from BIDS apps
\href{https://bids-apps.neuroimaging.io/apps/}{(https://bids-apps.neuroimaging.io/apps/)} 
and 18 from Boutiques. In fact, at the time of the study, BIDS apps had 27 images,
out of which one wasn't available on DockerHub. Boutiques had 49 images, listed using
Boutiques \texttt{bosh search} command,
however, only 23 unique images were listed, out of which 3 couldn't be retrieved and 2
 were already included in BIDS apps. All the final 26 images
from BIDS apps are Docker images, whereas Boutiques contains 18 Docker images
and 6 Singularity images.

\subsection{Image Scanners}

We use four popular image scanners, namely Anchore~\cite{github_2019},
Vuls~\cite{future-architect_2019}, Clair-scanner~\cite{arminc_2019} and
Stools~\cite{stools}. Anchore, Vuls and Clair-scanner support Docker
images while Stools supports Singularity. Different vulnerabilities may be
reported if scanning experiments take place on different dates.
To avoid such discrepancies, we freeze the vulnerability
databases used by these scanners as of 2019-09-25, when we initiate our
experiments. This allows for a fair comparison between the scanners.

\subsubsection{Anchore}

Anchore is an end-to-end, open-source container security platform. It
is a static
scanning tool that analyses container images and lists OS
packages, non-OS packages (Python, Java, Gem, and Npm), and files.
Anchore Engine can be used in two ways: through Docker image or Anchore
Command Line Interface (CLI).
It can be
installed directly on the host and used to inspect images.
In our experiments, we use Anchore Engine version 0.5.0 through Docker image \todo{insert name}, and
Anchore vulnerability database version 0.0.11.

Anchore compares package versions, which are present inside the
image, with the vulnerability database in order to flag vulnerabilities.
To get a vulnerability feed of various OS distributions, Anchore refers to
different sources, for instance, Ubuntu launchpad database to get
vulnerability data related to Ubuntu.

\subsubsection{Vuls}

Vuls is an open-source vulnerability scanner for Linux and FreeBSD. It
offers both static and dynamic scanning, and both local and remote
scanning. In our experiments, we use remote dynamic scanning, that is, Vuls
starts a container for every image to test, and queries the package manager in the image through SSH.
We use Vuls 0.9.0, executed through Docker image \todo{add Docker image name}. Vuls gets data from the Open Vulnerability and Assessment Language (OVAL) database.
It is worth noting that there is no OVAL data for Ubuntu 17.04 and 17.10 distributions,
meaning that images with these distributions cannot be scanned with Vuls.

\subsubsection{Clair-scanner}

Clair-scanner is a static vulnerability scanner for Docker containers.
It scans the image, prepares the list of
vulnerabilities, compares that list against a whitelist, and flags vulnerabilities
that are not present in the whitelist.
Clair-scanner utilizes the Ubuntu CVE tracker to obtain  Ubuntu vulnerability feed.
For that purpose, a Docker image is maintained that contains the Ubuntu CVE tracker database.
Whenever Ubuntu updates its database, this image is also updated with the required information.
We use Clair-scanner version 2.0.6, executed through  Docker image arminc/clair-local-scan:v2.0.6. 
We use another Docker image (arminc/clair-db:latest) for the vulnerability database, which was
last updated on 2019-09-18.

\subsubsection{Stools}

\todo{remove mentioning of CI, rewrite this paragraph.}
Continuous Integration (CI) allows smaller code changes, fault isolations,
faster release date, etc. Two types of CI are commonly used : TravisCI and
CircleCI. The former targets open source projects that need to be tested in
different environments, whereas the latter targets smaller projects where
integration needs to be done as fast as possible. 

Stools uses CoreOS's Clair, which
is used for Docker images, in combination with CI to allow scanning of
Singularity images.
It involves spinning a Clair container during testing and building a
Singularity image, and scanning it before the image is finalized.

In our experiments, we use a Docker image (\href{https://hub.docker.com/r/vanessa/stools-clair}{vanessa/stools-clair:v3.2.1})
following the steps mentioned in \href{https://github.com/singularityhub/stools}{Stools Github} for scanning
Singularity images.

\subsection{Linux Releases and Vulnerability Databases}

Through our experiments, we find that image scanners report vulnerabilities 
differently depending on the different Linux release types. So, it is 
important to provide an overview of these Linux releases types. 
BIDS app and Boutiques images in our experiments have diverse Linux
distributions, such as Ubuntu, CentOS, Debian, and Alpine. Further, a particular
distribution has different releases in general. To illustrate, we here examine Ubuntu as an example,
since it is heavily utilized in our experiments. 
\todo{Explain the situation with centos, update figure 3 accordingly.}
However, other distributions also have
similar release trend. Ubuntu releases
can be of two types: Regular or Long Term Support (LTS).
Regular release is supported only for 9 months, whereas LTS is supported for 5 years. Once LTS support
reaches End-Of-Life (EOL), Ubuntu decides whether to provide extended security support or not, which comes
in the form of Extended Security Maintenance (ESM) release.
ESM is a paid service that can be requested from Ubuntu to get security 
updates even after the EOL of a particular Ubuntu release. ESM and LTS releases of a particular Ubuntu distribution have different vulnerability
databases, because after EOL of a release, a vulnerability is fixed only in packages of ESM; however, it still
exists in LTS.

As an example, Ubuntu has ended support for some releases, such as 14.04 LTS,
17.04, and 17.10, as they reached EOL. However, Ubuntu decided to provide optional extended support for Ubuntu 14.04.
To use this extended support, users have to purchase ESM release for Ubuntu 14.04.
The images in our experiments have Ubuntu 14.04 LTS, so scanners should refer
to LTS release only while collecting data from the vulnerability databases.
More interestingly, scanners are able to refer to ESM release vulnerability database
even without purchase, however, this may lead to discrepancies in results.
%If scanners refer to ESM release for 
%vulnerability data, it may lead to discrepancies in results.
Further, if an image is using a Linux release where EOL has been reached that image may
turns to be vulnerable as it is not possible to retrieve any updates.
%Also, if ubuntu release with ended support is used in images, there are no chances of getting updates, hence
%resulting in vulnerable images. 

Ubuntu maintains its vulnerability database in the Ubuntu Launchpad or the Ubuntu CVE Tracker. For a given CVE, there is an entry for all ubuntu releases.
Ubuntu releases are listed with the package name
in which vulnerability exists and are entitled a status
(\href{https://git.launchpad.net/ubuntu-cve-tracker/plain/README}{https://git.launchpad.net/ubuntu-cve-tracker/plain/README}), which is
encoded in the following form:
\newline \\
\noindent <release>\_<source-package>: <status> (<version/notes>) \\
\newline\\
For a given release, the status can be any one of the following:

\textbf{DNE (Does Not Exist):} The package does not exist in the
		archive.

\textbf{needs-triage:} The vulnerability of this package
		is not known, and hence evaluation is needed.

\textbf{not-affected:} The package, while related to the
		CVE in some way, is not affected by the issue. Notes should
		provide detailed information, if needed. For instance, if the given
		status is "not-affected (1.14.6-1.1)" then this indicates that this specific
		package version is not affected.

\textbf{needed:} The package is vulnerable to the
		CVE and needs to be fixed.

\textbf{active:} The package is vulnerable to the
		CVE, needs fixing, and is actively being worked on.

\textbf{ignored:} The package, while related to the
		CVE in some way, is being ignored for some reason. The
		<notes> should provide that reason. For instance, if status looks like
		"ignored (reached end-of-life)", this means that the given Ubuntu release already reached
		end-of-life, so this CVE is ignored by Ubuntu. However, if there
		is extended security support for this release then this
		CVE will be handled in ESM release.

\textbf{pending:} The package is vulnerable and
                  has been fixed but an update has not been yet uploaded or
		  published. The <version> is given to indicate the particular 
		  version where the fix has been done.

\textbf{deferred:} The package is vulnerable, but 
                   its fix has been deferred for some reason. The <notes>
		   should provide further details. If a date is mentioned, e.g.
		   "deferred (2015-02-02)", the given date specifies the date when
		   the CVE was deferred.

\textbf{released:} The package was vulnerable, but
		an update has been already uploaded and published, e.g. "released (1.2.3)",
		<version> indicates the first version where the fix was applied.

\textbf{released-esm:} The package was vulnerable and
		an update has been already uploaded and published. However,
		this update is published in the Ubuntu ESM release only and not in LTS.
		The fixed version of such packages is appended by either
		+esm or \char`\~esm, indicating that this package version is available
		only via ESM.

Figure~\ref{example} illustrates how the information of a CVE is represented
in the Ubuntu launchpad database.

\begin{figure}[!ht]
	\fbox{{\includegraphics[scale=2.5,width=\columnwidth]
	{Figures/vulnExample2.png}}}
        \caption{\label{example} Representation of a CVE in Ubuntu Launchpad}
\end{figure}

%\begin{figure*} \centering{
%\includegraphics{status.pdf}}
%\caption{Experiment 1}
%\end{figure*}  


%\includegraphics[width=300, max width=\textwidth]{status.pdf}

%\begin{table*}[!ht]
%\csvreader[%
% respect all,%
%  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
%      \begin{adjustbox}{max width=\textwidth},
%  after reading=\end{adjustbox},
% tabular={c |c | c | c | c | c | c | c| c | c},
%	table head =Image Labels & {Image names} & {Anchore} & {Clair} & {Vuls} &{Stools} & {a} & {b} & {c} & {d}\\\hline,
% late after line= \\,
%        late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
%]{status.csv}{}{\csvlinetotablerow}%
%       \centering
%        \caption{\label{status}Number of vulnerabilities by scanners}
%\end{table*}

\section{Our Approach}

In this section, we present our approach, where we attempt the reduction
of security vulnerabilities in images by updating or
shrinking these images.

\subsection{Image Update Process}

If vulnerabilities exist in the container images, then our first approach
is to update these images in order to see the effects of such updates
on the vulnerabilities.
Updating an image involves updating all software packages that are
inside that image. We use a 
\href{https://github.com/kaurbhupinder/Vulnerability-Analysis/blob/master/Scripts/update/update.sh}{bash script} 
to update all images. That script checks the
package manager, which is present inside the image, and updates the image
accordingly. However, this action affects the reproducibility
of that image. For example, if a package is used by a scientist to conduct an experiment
and later that package is updated, other scientists want to reproduce initial results may actually
get different results due to updates.
%which means that the image cannot be used to verify the research
%findings of other scientists.

\subsection{Image Reduction/Minimization Process}
On the other hand, if it is desired to reduce the number of vulnerabilities without affecting the reproducibility of the image,
then we revert to image size reduction instead of image update. An interesting choice to do so would be to use 
Neurodocker~\cite{neurodocker}.
This tool traces and deletes unnecessary files.
However, it does not affect the number of installed packages.
Since image scanners report vulnerabilities according to the installed
packages. Therefore, after
minimization the same number of vulnerabilities is still reported.
Consequently, we need to reduce the number of installed packages
in the images by deleting unnecessary packages. For that, it is required to figure
out which packages we need for the pipeline to function properly. To allow for that, we utilize
Reprozip~\cite{rampin2016reprozip}, which is a tool that
is used to make applications reproducible. This tool traces operating system calls used by the
application while execution, and then based on this trace, it recognizes binaries, files, environment variables,
and library dependencies that are used by the application for future re-execution. If the OS is
Debian or RPM-based, Reprozip also
uses an available package manager to acquire a list of distribution packages from where these files come from.
So, a list of packages that are needed for the application re-execution is determined. Following that, the list
is expanded by adding important and required packages that are essential
for the system to function. Finally, we figure out all the dependencies of these packages using Debtree
~\cite{debtree}.
Effectively all needed packages are kept and remaining unnecessary packages are removed. We use
\href{https://github.com/kaurbhupinder/Vulnerability-Analysis/tree/master/Scripts/minification}{bash scripts} for
the image size reduction process, which install Reprozip in the image, collect Reprozip trace, and
finally delete all unnecessary packages.

Following the above two approaches, we employ a hybrid approach, where
we combine both update and size reduction processes in an attempt to
lessen number of vulnerabilities or to test the effect of
combining two approaches. To allow for that, we first update all packages
the image, then delete all unnecessary packages. Applying these processes in reverse
may reduce the needed work; however this is not possible in all cases. For instance,
some packages, such as apt-transport-https, are required to fetch updates, deleting these packages
ahead of time will disallow the update process to take place.
%Finally, we combine both update and size reduction process
%to lessen the number of vulnerabilities.
%Therefore, in this process we first update all the packages in the image and then deletes
%the unnecessary packages. For this process we used the same scripts that
%we used for earlier experiments.
%\begin{comment}
%\subsection{CBRAIN}
%
%\href{http://github.com/aces/cbrain}{CBRAIN}~\cite{sherif2014cbrain} is a web portal that is
%used for the processing of distributed data on various storage locations of computing
%clusters. CBRAIN system deployed by Montreal Neurological Institute depends on the infrastructure
%delivered by Compute Canada~\cite{das2016mni}.
%It is also used by CONP to exploit services of Compute Canada. CBRAIN is a collaborative
%neuroimaging research platform that is active in production since 2009. CBRAIN
%provides transparent access to various distributed storage sites and computing
%resources across the world. CBRAIN’s infrastructure consists of three main
%layers, namely access layer, service layer, and infrastructure layer~\cite{sherif2014cbrain}. The access
%layer is for CBRAIN users, and can be accessed through any modern browser or
%RESTful API. The service layer consists of CBRAIN portal, which contains
%metadata and databases. It provides information about users, their permissions,
%resources etc. The infrastructure layer consists of data resources and computing
%resources, which are connected through a network. 
%CBRAIN supports Docker, Singularity, BIDS apps, and Boutiques.
%CBRAIN users uses a portal
%account on the cluster. Users are only able to
%run pre-defined applications on the cluster through the CBRAIN portal.
%\end{comment}
\section{Results}

In this section,
we first discuss our detected vulnerabilities in the images, using the three scanners, and compare the
results. We then discuss the effect of the image updating/minimizing and applying the hybrid
approach on the detected vulnerabilities.
Lastly, we do an analysis of obtained results and explain the reasons behind our
findings.

\subsection{Detected Vulnerabilities}

Table~\ref{table1} shows the number of detected vulnerabilities in the different images,
detected by each of the scanners.
Interestingly, our experiments concluded considerable discrepancies in the results obtained by
these scanners. In particular, in most cases,
Anchore reports more vulnerabilities than Vuls and Clair-scanner resulting in 
the Jaccard coefficient of 0.59 with both,
whereas Vuls and Clair-scanner share more common vulnerability detection resulting to the Jaccard coefficient of 0.83.

Figure~\ref{fig:graph1} provides more image-specific information.
It represents the number of vulnerabilities that are present inside images.
The overall trend shows that as the number of packages increases in the image, the number of vulnerabilities
also get increased.
The figure also infers that Alpine distribution, being a
lightweight distribution, has the least number of vulnerabilities, whereas more vulnerabilities are reported for
Ubuntu as it contains more packages.
We also analyze that out of the total Docker images scanned by our experiments, Debian reports more high vulnerabilties, as
classified by databases, than others.
%\begin{table*}
%\csvreader[%
% respect all,%
%  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
%      \begin{adjustbox}{max width=\textwidth},
%  after reading=\end{adjustbox},
% tabular={c |c | c | c | c |c},
%	table head =Image Labels &{Image names} & {OS} & {Anchore} & {Clair} & {Vuls}\\\hline,
% late after line= \\,
%        late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
%]{results.csv}{}{\csvlinetotablerow}%
%       \centering
%	\caption{\label{table1}Existing number of Vulnerabilities}
%\end{table*}



\begin{table*}[!ht]
\csvreader[%
 respect all,%
  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
      \begin{adjustbox}{max width=\textwidth},
  after reading=\end{adjustbox},
 tabular={c |c | c | c | c |c},
	table head =Image Labels &{Image names} & {Anchore} & {Clair} & {Vuls} &{Stools}\\\hline,
 late after line= \\,
        late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
]{fullresults.csv}{}{\csvlinetotablerow}%
       \centering
        \caption{\label{table1}Number of vulnerabilities by scanners}
\end{table*}

\begin{figure*}[!ht]
        {\includegraphics[scale=1.5,width=\textwidth]
        {Figures/vulngraph.pdf}}
        \caption{\label{fig:graph1} Number of vulnerabilities by packages}
      \end{figure*}

\begin{figure}[!ht]
        {\includegraphics[scale=2.5,width=\columnwidth]
        {Figures/venn.pdf}}
        \caption{\label{fig:venn} Scanner results}
\end{figure}

%\begin{figure*}[b]
%        {\includegraphics[width=\textwidth]
%        {Figures/vulnwithupdate.pdf}}
%        \caption{\label{fig:graph2} Number of vulnerabilities before and
%        after update of the images}
%      \end{figure*}

\subsection{Discrepancies between Scanners}

Figure~\ref{fig:venn} represents the number of vulnerabilities reported by
the scanners and the overlap between them.

We find a total of 20,050 vulnerabilities in BIDS apps and Boutiques images.
It is interesting to note that out of these vulnerabilities, 4453 vulnerabilities are only
reported by Anchore, 673 by Clair-scanner, and 325 by Vuls.

As the number and type of vulnerabilities reported by the three scanners are significantly different from each other,
we desire to investigate the reasons behind these differences.
%these scanners report different numbers and types of vulnerabilities.
%How their logic differs and what exactly is making these results different than each other.

Following our investigation, we are able to explain some of the reasons behind
the differences. 
Such reasons were resulted from the way these scanners function or behave 
in particular, the following actions by the scanners are indicative:
\begin{itemize}
   \item scanners ignoring vulnerabilities in Linux-kernel-header packages,
   \item scanners referring to different vulnerability databases,
   \item different frequency of updating their databases,
   \item bugs in scanners. 
\end{itemize}

Below, we explain these reasons in further details and provide examples
for clear illustrations.
%these reasons include
%some scanners ignoring vulnerabilities in Linux-Kernel header packages, scanners referring to different databases,
%how frequently they are updating their databases, and bugs in scanners, etc. 
%We explain these differences below in detail
%and provide an example with each reason to make it clear.
%
%\begin{comment}
%Venn Diagram~\ref{fig:venn} illustrates that Anchore reports 4453 different vulnerabilities that are reported
%by Vuls and Clair. Out of this 4443 vulnerabilities are present in linux-kernel-headers. These are ignored by
%both Clair and Vuls.
%\end{comment}

\textbf{Linux-kernel-headers:} Clair-scanner and Vuls are ignoring all vulnerabilities in the Linux-kernel-headers,
whereas Anchore reports all of them.
We find that 4443 out of 4453 vulnerabilities that are only reported by Anchore are present in Linux-kernel-headers.
For example CVE-2019-9506 present in Linux-libc-dev-4.4.0-31.50, which is reported by Anchore, is not
detected by both Vuls and Clair-scanner.
Linux-kernel-headers are the headers files that only provide function names, their parameters, and their
return types.
The actual source code of these functions is present in the Linux kernel and is not inside the image.
So, vulnerability detection in header files
is irrelevant in this case.

\textbf{CVEs with Status as “Not-affected”:} Vuls is reporting vulnerabilities that have status
as "not-affected" in the vulnerability database. It means Linux distribution which is inside the image is not affected
by the particular CVE. In other words, Vuls is reporting vulnerabilities that it should not have been reported.
For example, we scan an image having the Trusty release in it and Vuls is reporting CVE-2015-2305
in the package Cups. However, upon checking the vulnerability database, we find that package Cups in Trusty is not
affected by this CVE.

\textbf{CVEs with status as "Ignored (reached end-of-life)":}
Some vulnerabilities are ignored in Ubuntu 14.04 LTS as it reached end-of-life. 
However, in Ubuntu 14.04 ESM release, these vulnerabilities may or may not be present.
Anchore checks the last status of these vulnerabilities whether the package was vulnerable to the CVE
prior to the end-of-life. Only if it was vulnerable, Anchore reports it, otherwise it does not.
If this kind of vulnerability is present in ESM release then Clair-scanner reports it because it
only refers to ESM release. On the other hand, if the vulnerability
status in ESM release is "DNE" (Does Not Exist), then Clair-scanner does not report it. 
For example, CVE-2017-9994 vulnerability in Libav package is ignored in Trusty LTS release due to end-of-life.
Consequently, it is not reported by Anchore. This vulnerability has status as "DNE" in Trusty ESM
release so Clair-scanner also does not report it. As Ubuntu 14.04 LTS release is present inside the images,
Clair-scanner still refers to Ubuntu 14.04 ESM release vulnerability database, which is incorrect.

\begin{figure*}[!ht]
        {\includegraphics[width=\textwidth]
        {Figures/vulnwithupdate.pdf}}
        \caption{\label{fig:graph2} Number of vulnerabilities before and
        after update of the images}
      \end{figure*}


\begin{figure*}[!ht]
        {\includegraphics[scale=1.5,width=\textwidth]
        {Figures/bargraph.png}}
        \caption{\label{fig:bargraph} Vulnerabilities by different experiments}
      \end{figure*}
\textbf{Vulnerabilities not present in Ubuntu 14.04 ESM release:} These vulnerabilities are not present in Ubuntu 14.04 ESM so they 
are not detected by Clair-scanner but they affect Ubuntu 14.04 LTS, and hence detected by Vuls. The CVE-2017-1375 is an example
of such vulnerabilities.

\textbf{False negatives:} False negative reporting is detected. Clair-scanner and Vuls
are missing vulnerabilities that they should have detected. For example, the CVE-2016-9082 
is present in package Cairo in Xenial release and it is not detected by Clair-scanner.
Vuls is also missing vulnerabilities such as CVE-2019-5094.

\textbf{False positives:} False positive reporting is also detected. For instance,
there are false positives in clair-scanner.
Some vulnerabilities are not linked to Ubuntu 14.04 LTS which is 
present inside the image, however, Clair-scanner have reported such vulnerabilities.
For instance, CVE-2019-1274 is an example of such vulnerabilities. 
%is showing because these vulnerabilities are present in Ubuntu 14.04 ESM and 
%Clair is only referring to Ubuntu 14.04 ESM release. 
%The reasons of Clair showing
%false positives and false negatives are unclear. We reported this issue on two Google groups of Clair i.e CoreOS Dev and
%clair-dev \href{https://groups.google.com/forum/\#!topic/clair-dev/8IqCCfd-EEc}{(https://groups.google.com/forum/\#!topic/clair-dev/8IqCCfd-EEc).}

\textbf{Database difference:} At the time we pulled Clair-scanner's database, it was one week old.
                              As a result some vulnerabilities were not updated. For instance, CVE-2019-5094, which
		              was published on 2019-09-24, was not 
		              updated in Clair-scanner's database. Due to which it is missed by Clair-scanner.
			      Consequently, these discrepancies, even small, are sufficient to change the detection of
			      the scanners.

\textbf{Epoch bug:} There is a bug in the Anchore scanner due to which some vulnerabilities are 
		not detected by Anchore. This bug gets triggered when a package’s version have epoch 
		(1:3.3.9-1ubuntu2.3) in it. For example, CVE-2018-1125 in Procps package is not
		detected by Anchore due to the presence of epoch in the Procps package version.
		We reported this bug to the Anchore development team through their Slack channel.

\textbf{CVEs with status "Ignored (out of standard support)" bug:} There is another bug in Anchore due to 
		which it is not able to detect some vulnerabilities. Due to this bug, Anchore does not detect 
		vulnerabilities that have a status as “ignored (out of standard support)” in Ubuntu 14.04 LTS. 
		However, if this vulnerability is present in Ubuntu 14.04 ESM release, it is detected by Clair-scanner. 
		For instance, CVE-2019-13565, which is present in Ubuntu 14.04, is an example of such vulnerabilities. 
		We reported this bug as well to the Anchore development team through their Slack
		channel.

\textbf{Rejected CVEs:} There are some CVEs, such as CVE-2017-13753, that are rejected because they are duplicate copies of other CVEs. 
	So, Anchore is not reporting those rejected CVEs, but Vuls is reporting them.
%\begin{table*}
%\csvreader[%
% respect all,%
%  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
%      \begin{adjustbox}{max width=\textwidth},
%  after reading=\end{adjustbox},
% tabular={c |c | c | c | c |c |c |c |c},
%	table head =Image Labels &{Image names} &{OS Distro} & {Vulnerabilities by Anchore} & {Vulnerabilities by Clair} & {Vulnerabilities by Vuls} & {a} & {b} & {c}\\\hline,
% late after line= \\,
%        late after last line=\\\hline
%]{status.csv}{}{\csvlinetotablerow}%
%       \centering
%        \caption{\label{status}Existing number of Vulnerabilities}
%\end{table*}
%\begin{comment}
%The next experiment involves updating all these images and then rescanning them to see how the number of
%vulnerabilities drop inside them. We used a \textit{bash} script to update these images. This script is
%present in our Github repository \href{https://github.com/kaurbhupinder/Vulnerability-Analysis}
%{https://github.com/kaurbhupinder/Risk-to-Clusters-Paper}. This script 
%will find the package manager inside the image and then update the image according to the package manager it finds.
%\end{comment}

\subsection{Effect Of Update}
As a result of image updating,
scanning results change significantly.
%However, there are still
%vulnerabilities reported by these scanners but there are no fixes available for these vulnerabilities
%to date.
%\begin{comment}
%There are only two
%options, either you accept those vulnerabilities and use that image, or you discard that image.
%So one thing is clear here that even if we keep our images up to date there will be still some
%vulnerabilities that we have to face.
%\end{comment}
Figure~\ref{fig:graph2} represents the number of vulnerabilities that are detected by Anchore before and after 
image update. 
%In fact, this figure depicts an additional results of update to the original Figure~\ref{fig:graph1}.
In fact, this Figure combines the original results of Figure~\ref{fig:graph1} with the results of the image update
experiment.
Clearly, the figure illustrates that when image are updated, the number of vulnerabilities reduces by a
significant number. Furthermore, a mild slope of vulnerabilities after the image update shows that
there is a set of packages that contain vulnerabilities and have not been fixed yet. Also, these
vulnerabilities mostly have \textit{Low, Negligible, or Medium} severity status, meaning that
high vulnerabilities are prioritised and fixed fast.
Besides that, it is also interesting to note that some images in Figure~\ref{fig:graph2}
do not have update results. This is because some Linux distributions reached end-of-life and
are not being updated anymore.
Despite of the significant drop in the number of vulnerabilities as a result of image updating,
there is still a number of vulnerabilities reported by the scanners. There is due to the
vulnerabilities which do not have fix yet.

%After the update, the vulnerabilities mostly have \textit{Low, Negligible or Medium} severity status.
%Also, after the update, the number of vulnerabilities have a mild slope meaning that there
%are a fixed set of packages that contain vulnerabilities and have no fix yet.
%\begin{figure*}[h]
%        {\includegraphics[width=\textwidth]
%        {Figures/vulnwithupdate.pdf}}
%        \caption{\label{fig:graph2} Scatterplot representing the number of vulnerabilities before and 
%	after update of the images}
%      \end{figure*}

%\begin{figure*}
%        {\includegraphics[scale=1.5,width=\textwidth]
%        {Figures/graphwithdeletedpackages.pdf}}
%	\caption{\label{deleted}\#Deleted Packages vs \#Reduced Vulnerabilities}
%\end{figure*}

\subsection{Effect Of Size Reduction}

Our second approach involves the deletion of unnecessary packages from the images.
We tested our approach on 5 different images. We find that
after the size reduction process, sometimes the scanning results deviate only a little from the results
without minimization. While the minimization process results in significant reduction
in the number of vulnerabilities in some cases, we find that in other cases the effect
is negligible. In other words, the image reduction was inconsistent.
%At first, we thought that we will have a notable effect of size reduction on
%vulnerabilities. However, this is not the case always. The bar graph shown in
%Figure~\ref{fig:bargraph} illustrates that images \textit{bids/ndmg} and
%\textit{poldracklab/fmriprep:1.2.3} have an insignificant effect of size reduction.
According to our analyses, this can be due to two reasons: \rom{1}) the number of
deleted packages
and \rom{2}) the kind of deleted packages. 
For an instance, if the deletion is for a package that includes a lot of vulnerabilities,
that particular deletion naturally results in the drop of number of vulnerabilities.
In other
words, deleting more packages reduces more vulnerabilities. 
For instance, we were able to delete only 21 and 25 packages for 
\textit{bids/ndmg} and \textit{poldracklab/fmriprep:1.2.3} images. Consequently, vulnerabilities
reduced only by 4 and 17 respectively. 
Also, if we delete packages that contain a lot of vulnerabilities, it helps in reducing
vulnerabilities by a significant number. For instance, in case of our experiments
deleting compilers and Linux-kernel-header packages helped to minimize vulnerabilities
by a significant number in \textit{bids/example, bids/freesurfer, and bids/mindboggle:0.0.4-1}. 
%Our third experiment shows that deleting unnecessary packages from the image also helps to reduce
%the number of vulnerabilities by a significant number. We started this experiment with
%\textit{bids/example} image and deleted 61 unnecessary packages out of total 528 packages, which helped
%to reduce 838 vulnerabilities to 523. Later, we also checked with \textit{bids/freesurfer} image, which allowed
%to delete 71 unnecessary packages out of total 298 packages. Consequently, reducing number of vulnerabilities
%from 353 to 101.

\subsection{Combined Effect Of Update and Size Reduction}

Our last experiment includes updating the image and then removing unnecessary packages from it.
Figure~\ref{fig:bargraph} displays the results. 
Our initial thought was that with the update and size reduction process together, we will be able to
reduce vulnerabilities even more. However,
we analyzed that this is not always true. Again, it depends on which packages are deleted and how
many vulnerabilities they contained. To illustrate, \textit{bids/example} image in Figure~\ref{fig:bargraph}
shows no effect of size reduction along with update process. It has 181 vulnerabilities for both experiments 2 and 4.
Meaning that packages, which we deleted after updating the image, were already vulnerability free. Therefore,
scanning results did not change.


% Would the results apply to other domains than neuroimaging



\section{Discussion}

As we noticed that none of the Boutiques and BIDS images at the time of the study are free of vulnerabilities, out of which
so many are high vulnerabilities as well. Yet there is not a single image scanner on which we can rely upon for
scanning. Additionally, we cannot update all images because some OS releases, which are used inside images, 
already reached end-of-life and are
no longer getting updates. Furthermore, the minimization of images is a time consuming process. As we have to run
the pipeline to get Reprozip trace that can take up to several hours. Also, the user should have proper knowledge
of running the pipeline because it is image specific. In addition to that, Reprozip can be only installed
in the images having Python version 2.7.3 or greater, or 3.3 or greater. Above all, there is no guarantee that
the commands that you ran to get Reprozip trace covered the whole program, maybe it runs a particular
branch of the program. So there should be some kind of coverage measurement.
Besides this, as scanners report vulnerabilities according to the versions of the installed packages,
they are likely to miss packages that are not installed using package manager. 
Therefore, we suggest some particular rules that can be
followed to keep container images safe.
\newline 1. Update packages regularly.
\newline 2. Remove unnecessary packages, in particular the ones used for installation (compilers, source packages, etc).
\newline 3. Choose your base OS image wisely.
\newline 4. Run image scanning tools in CI scripts. For instance Anchore.
\newline 5. Protect your GitHub/DockerHub credentials because if automated builds is set up
in Docker Hub, it can automatically build images from external repositories, for instance GitHub.
\newline 6. Minimize dependencies.
\newline 7. Avoid static linking because it obfuscates vulnerability scanning.
\newline 8. Use the package manager to facilitate vulnerability detection.
\newline 9. Use OS releases that have LTS support.
\newline 10. Sign your images. Docker Content Trust (DCT) provides ability to digitally sign
images to verify the integrity of the images.

\section{Conclusions and Future Work}


In this paper, we performed various experiments to study the security state of the Docker
and Singularity images, which are used in the neuroimaging field. We found out strong correlation
between the number of packages and the number of vulnerabilities in the images, which implies
that the number of vulnerabilities increases with the number of packages. We also found out that
updating images reduces the number of vulnerabilities by a significant number. However, for some
vulnerabilities there are no fixes available yet so the images cannot 
be made totally invulnerable. Continuing with our next two experiments, we analyzed that the
image size reduction process also reduces vulnerabilities a lot. However, we found out that this is not
always true. It depends on two factors: kind and the number of packages that we are
deleting.

In future work we would like to see how these vulnerabilities can be leveraged
to design attacks from containers. Particularly, we want
to consider web servers and clusters that processes data using containers.

\bibliography{bibliography}


\end{document}

