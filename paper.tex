% GigaScience template
\documentclass[a4paper,num-refs]{oup-contemporary}

\journal{gigascience}


%%%% Packages %%%%
\usepackage{siunitx}
\usepackage{algpseudocode} % Algorithmic environment
\usepackage{xspace}
\usepackage{minted} % Used for JSON highlighting
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{makecell}
\usepackage[flushleft]{threeparttable}

%%%% Commands %%%%
\newcommand{\todo}[1]{\color{red}\textbf{TODO:}#1\color{black}}
\newcommand{\note}[2]{\color{blue}Note: #1\color{black}}
\newcommand{\reprozip}[0]{ReproZip}
\newcommand{\TG}[1]{\color{blue}From Tristan: #1\color{black}}

\title{Risks of Running Vulnerable Container Images for Data Analysis on HPC
Clusters}
  
\begin{document}

\author[1]{Bhupinder Kaur}
\author[1]{Aiman Hanna}
\author[1]{Tristan Glatard}

\affil[1]{Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada}

\maketitle

\begin{keywords}
Containers; Security; Docker; Singularity; Neuroimaging.
\end{keywords}


\section{Introduction}

Containers, which provide operating system (OS) level virtualization, are very
popular. This is because they are very lightweight, flexible, resource-efficient,
provide fast development cycles, continuous delivery,
and cost reduction of infrastructure. OS-level virtualization gained a lot of interest when Docker was
introduced in 2013~\cite{gantikow2016providing}. However, it has security concerns due to which it
is not supported by High Performance
Computing (HPC) environments. As a result, Singularity came in 2016 with the goal of providing support
for HPC environments. It is used in many clusters including Compute Canada.
Table \ref{fig:cluster_list} illustrates the reported usage of Singularity on HPC clusters~\cite{kurtzer2017singularity}.


\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{Figures/cluster_list.png}
	\caption{List of HPC clusters using Singularity~\cite{kurtzer2017singularity}.}
	\label{fig:cluster_list}
\end{figure}


No doubt containers have gained a lot of popularity, however containers tightly
integrate with the host due to the sharing of the kernel, 
mounted file systems, and devices, which raises security
concerns. Figure \ref{fig:container-overview} provides overview of the containers architecture.
They also share three main security threats with other virtualization
techniques~\cite{gantikow2016providing}.

\begin{figure}
  \centering
  \includegraphics[width=.7\columnwidth]{Figures/container.png}
  \caption{Architecture of Container-based
                Virtualization.}
  \label{fig:container-overview}
\end{figure}

\textit{Privilege Escalation} A malicious attacker can break out of the container
and gain control of the host system and other containers running on the same host.

\textit{Denial-of-Service} One container may end up eating all the resources of the
host hence resulting in the starvation of the host and other containers.

\textit{Information Leak} Private data of the host and other containers could be
leaked and can be used for further attacks.


However, two features of the Linux kernel, \textit{control groups} and \textit{namespaces},
are used by containers to mitigate these threats to a certain extent. Security
of containers is still most concerning issue. According to a Forrester survey~\cite{} done in January
2015, security is the
biggest concern while deploying containers.
Except web applications, containers are also popularly used for scientific computing
and data science in neuroscience. In fact, Singularity was developed for scientific applications
by keeping focus on HPC environments. This popularity of containers lead us to the
primary research question of this work: \textit{what is the current security state of
container images that are deployed on HPC clusters}.

To answer that question, we scan all images that are used on Compute
Canada clusters by neuroscience field. Scanning refers to the practice of
collecting all information about the container image, investigating it
for vulnerabilities, and finally producing a
report to summarize scanning results. It is broadly categorized into
two types: static scanning and dynamic scanning. The former scanning technique
involves extracting information of an image without running it into a container,
whereas the latter approach involves launching the container from the target image, and
then scanning the running container.
Here, we focus mainly on vulnerability scanning and not on malware.
Malware is a computer software that is specially designed to attack the target computer,
whereas vulnerability is a weakness in the developer's software that can be used
by the attacker to perform unathorized actions on the target computer.
In this paper, we report all vulnerabilities that are present in
container images, specifically used by neuroimaging field, and access their
related risks for data analysis. Particularly, we aim to answer three primary
research questions:

\textit{RQ1:} Are vulnerabilities present inside container images that are
deployed on HPC clusters?

\textit{RQ2:} Can we get rid of these vulnerabilities by updating the
images?

\textit{RQ3:} Can we get rid of these vulnerabilities by shrinking the
size of the image?

To answer those questions, we take an example of neuroscience field where
containers are used on Compute Canada HPC cluster.
We are not the first to work on vulnerabilities inside container images but
the existing research work on containers focuses mainly on the security of Docker
containers.
This focus is justified by the fact that, containers expose the host's resources
(e.g., file system/ IPC) to the guest system. This feature raises a confidentiality
threat for the applications running on the same host. Previous studies evaluated
security of Docker engine ~\cite{martin2018docker, sultan2019container, combe2016docker, bui2015analysis},
and have scanned vulnerabilities on Docker hub~\cite{Shu2017, gummaraju2015over}.
Also Singularity came up with Stools, which can be used for scanning Singularity images
for security and quality checks.
Here, we focus on the specific context of scientific data analysis on HPC clusters, taking
neuroimaging as an example.


\TG{paper suggested by Emad Shihab.}

This paper is organized as follows: in next section, we provide description
of materials and methods which includes summarizing a particular use case of
containers in neuroscience, which is used for scientific computing. It involves
usage of containers on shared HPC cluster. Additionally, in this section we
describe all the resources that are used by this use case. We also explain
scanning tools that we use for scanning container images to report
vulnerabilities. Next section of this paper is about the results. Here, we
present number and type of vulnerabilites that are present in the container images
which are used for data analysis on shared HPC clusters, and discuss how many of them are
critical vulnerabilities. Following section is about discussion of these results
where we provide more insight into the risks that are caused by these vulnerabilties
and how they can be leveraged to design attacks. Here, we also provide some such
vulnerability examples. Finally, we conclude this paper by discussing ten simple
rules that can be followed to secure container image for use in clusters.

\section{Materials and Methods}

As we are taking a particular use case of containers from
neuroscience field i.e Canadian Open Neuroscoence Platform (CONP) so  
in this section we summarize the data and tools 
that are used in CONP. CONP is a national platform for sharing neuroscience
research data and aims at creating an interactive interface for neuroscientists and
clinical neuroscience. The main goal of the CONP platform is to store, process, and
distribute massive amounts of data produced by modern neuroscience.
Here, we summarize all the resources that are
used by CONP to function.


\subsection{Container Engine: Singularity}

Singularity offers mobility of compute by facilitating portable environments 
through a single image file~\cite{kurtzer2016singularity}. Once Singularity image
is created, it is hashed by using SHA256 hashing. Hence, it cannot be changed
once it is created, consequently, it can be used for reproducing the results of
scientific experiments. Main features provided by
Singularity are mobility of compute and reproducibility~\cite{kurtzer2017singularity}.

Users can easily access files, devices, sockets, ports of the host system from
the Singularity container. By default, Singularity bind mounts /home/\$USER, /tmp, and \$PWD
into the running container. Additional directories can be specified with \textit{--bind}
to bind mount into the container. By defaut, Singularity uses as less as possible namespaces.
However namespaces can be requested if required. Users cannot escalate privileges inside
Singularty containers. This is because Singularity do not run containers as root.
Instead, a user inside Singularity container is the same user outside the container.


\subsubsection{Docker Engine}

Docker runs a software, \textit{Docker daemon}, on the host machine.
Docker daemon runs as root, and is remotely controlled through a
UNIX socket. It is responsible for launching containers, their
isolation, and spawning shells into the containers. It is also
responsible for managing Docker images i.e \textit{pull} and \textit{push}
from image repository, building images from Dockerfiles, signing them, etc..
When a Docker container runs, the container process is spawned as a
child of this root owned daemon. As Docker users directly interact with the
Docker daemon, it is possible to force Docker daemon to escalate privileges.
If a user gets \textit{root} privileges, it introduces unthinkable security risks
for multi-tenant shared enviornments. Due to this reason, Docker is not
supported by HPC environments. However, Docker containers can be imported into
Singularity and then used on HPC clusters.

\subsection{Container Image Formats}

A container image is a package that contains the application along with its
required dependencies and libraries.
Nowadays, two most popular containerization tools used are Docker and Singularity.
Both have different image format. Below we provide description of both image
formats.

\subsubsection{Docker Image Format}

Docker images are organized as a series of layers stacked on top of each
other and identified by unique layer identifiers. If a layer is reused
in different images it will
have the same id across images. Each layer consists of a filesystem diff
with respect to the layer below. DockerHub uses gzip compression for
transferring layers. There are two ways to create a Docker image. The
first is to use an existing Docker image as a base image and then build a
new image from that one, by making changes in the filesystem, which is
saved as a new layer of the Docker image. The second way is to build a new
Docker image from scratch. Docker supports several different storage drivers.
\textit{Overlay2} is the preferred storage driver used by Docker for all currently
supported Linux versions, whereas \textit{aufs} is preferred for Docker 18.06 and
older, when using Ubuntu 14.04 on kernel 3.13 as it do not support \textit{overlay2}.
Other storage drivers that are supported by Docker include \textit{devicemapper, btrfs,
zfs, and vfs}

\subsubsection{Singularity Image Format}

Singularity takes snapshot, locks, and archives the developed application,
which is known as Singularity image.
It means that Singularity image is a single immutable file that can be moved around as
any other file. This file can be checksummed, signed, and easily
used for verification purposes. Singularity containers use Squashfs file format
by default. However, it also supports two other formats i.e \textit{sandbox} format
(which is just a chroot
directory) and \textit{writable} format (the ext3 file system).
While publishing experimental results, authors can also publish Singularity
image along with its hash, which allow other researchers to verify results.

\subsection{Application frameworks}

We used containerized applications available in the Boutiques and BIDS Apps
frameworks used in neuroscience to run analyses on HPC clusters. 

\subsubsection{Boutiques}

Boutiques~\cite{glatard2018boutiques} is a application sharing system to
publish, integrate, and execute command-line applications across different
platforms. In Boutiques, the command-line of the application is described
through a flexible JSON descriptor pointing to a Docker or a Singularity
image where the application is installed. A set of core tools help
construct, validate, publish and execute Boutiques descriptors. Boutiques
applications are published on the Zenodo research repository.

We used the 49 Boutiques applications published on Zenodo at the time of
the writing. These applications use 23 different container images,
including 7 Singularity images and 16 Docker images.

\subsubsection{Brain Imaging Data Structure (BIDS) Apps}

BIDS apps~\cite{gorgolewski2017bids} is a framework designed to share and execute neuroimaging
analysis pipelines. It improves usability, accesibility, and reproducibility
of different applications through containerization.
Currently, there are 27 BIDS apps available and all are using different Docker images.

\begin{figure}
  \centering
	\includegraphics[width=\columnwidth]{Figures/bids_table.png}
  \caption{All Container images used by BIDS apps.}
  \label{fig:bids_apps}
\end{figure}

\subsubsection{ReproNim}

ReproNim is a Center for Reproducible Neuroimaging Computation. It is a vision
to help neuroscientists in reproducing neuroimaging research. Repronim
uses RepronIn, BrainVerse, Neuroimaging Computation Environments Manager (NICEMAN),
and NeuroBlast software tools for its
functioning. ReproIn is a software that automate acquisition and conversion
of collected MRI data to BIDS standard format with DataLad version management~\cite{kennedy2019everything}.
BrainVerse is a cross-platform software framework and collaborative desktop application
that helps in managing, tracking, and sharing information.
NICEMAN is a software system that tracks and manages available computation resources
and makes their use in a scalable and reproducible way.
Neuroblast is a service that facilitates data sharing of existing studies, and it also
helps users to search similar studies based on combination of analysis,
tasks and activation patterns. There are currently 28 different Singularity
images used by Repronim. 

\subsection{Other images}

\TG{We could also use selected images from DockerHub or SingularityHub. For
instances the ones used by AFNI or other neuroimaging tools not represented
in Boutiques or BIDS Apps. However we wouldn't be able to shrink these
images unless we identified specific command-lines to run.}

\subsection{Image Update Process}

If there exist vulnerabilities in the container image, then there are two ways
to proceed, either not to run that image at all, or run only after updating the
image. Updating the image involves updating all software packages that are
inside that image. However, this option effects the reproducibility
of the image, which means that the image cannot be used to verify research
findings of other scientists. An alternative approach can be to trim unnecessary
packages from images, which in turn reduces the number of vulnerabilities
present in images. To update container images we used a bash script
which is given in Figure~\ref{}.


\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               linenos=false,
               xleftmargin=0pt,
               tabsize=4]{bash}
#!/usr/bin/env bash

function die {
	echo $1
	exit 1
}

function find-pm {
		(type $1 &> /dev/null && echo "> Found $1") || \
		(echo "> $1 not found" && return 1)
}

\rm -f .updated
find-pm yum && (yum update -y && touch .updated) 
find-pm apt && (apt update -y && apt upgrade -y \
&& apt autoremove -y && apt autoclean -y \
&& touch .updated)
test -f .updated || die "Cannot find package manager \
or update failed"	       
\end{minted}
\caption{update.sh}
\label{listing:update.sh}
\end{listing}


\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               linenos=false,
               xleftmargin=0pt,
	       tabsize=4]{bash}
#!/usr/bin/env bash

set -ue

function usage {
	echo "$0 <image_list>"
	exit 1
}

if [ $# -lt 1 ]
then
	usage
fi

for image in $*
do
	echo -n "Updating image ${image}... "
	docker run -e /bin/bash -v $PWD:$PWD -w \
	$PWD ${image} ./update.sh &>${image}.log \
	&& echo "[ OK ]"
	echo -n "Commiting updated image... "
	ID=$(docker ps -a | head -2 | awk \
	'$1!="CONTAINER" {print $1}')
	docker commit ${ID} updated_${image} \
	&& echo "[ OK ]"
done
\end{minted}
\caption{update-images.sh}
\label{listing:update-images.sh}
\end{listing}


\subsection{Scanning tools used}

Out of the various container image scanning tools available to scan Docker images,
we selected Anchore
and Vuls because these are the most mature scanning tools. To scan Singularity images
we use Stools, which is specially designed for Singularity images. This tool internally uses
ClairScanner tool so we included ClairScanner also in our experiements to compare
performance of both the tools.

\subsubsection{Anchore}

Anchore is an end-to-end, open-source container security platform. Anchore
is a static
scanning tool that analyses container images and lists OS
packages, non-OS packages (Python, Java, Gem, and Npm), and files.
Anchore is a set of tools, which users can
employ for scanning container images and applying custom policies to them.
It provides visibility and transparency of the container environment.
Anchore offers services in two ways: Anchore Engine and Anchore Engine
Command Line Interface (CLI). Anchore Engine is available as a Docker
image, which is available on Docker Hub. Anchore Engine CLI provides
command line interface in addition to Anchore Engine REST API. Anchore
Engine CLI can be installed directly on the host and used to inspect
images.

\begin{figure}
  \centering
  \includegraphics[width=.7\columnwidth]{Figures/anchore.png}
  \caption{Databases used by Anchore.}
        \label{fig:anchore_db}
\end{figure}


\TG{You should refer to the vulnerability databases used, and explain how
software components, for instance files, are matched to these databases. Is
the matching based on file checksum?}

\subsubsection{Vuls}

Vuls is an open-source vulnerability scanner for Linux and FreeBSD.
It is an agentless vulnerability scanner and uses various
vulnerability databases. Using dynamic scanning technique, it offers
remote and local scan. Remote scan involves setting up only one machine, to
which other target servers are connected via SSH. Local scan involves running
the scan on the target server itself. Further, Vuls offer fast scan, fast root scan,
and deep scan.
Fast scan is performed without root privileges, whereas fast root scan is
performed with root privileges. The latter also uses checkrestart utility to 
detect processes that are updated but not yet restarted because if they are not
restarted, updates are not effective. So fast root scan also detects these pro-
cesses. Both fast scan and fast root scan are performed offline without Internet
access, and put almost no load on the scan target server. Deep scan uses
root privileges for scanning, and is used to get a more detailed scan. It checks
changelogs, which puts more load on the target server.

\begin{figure}
  \centering
  \includegraphics[width=.7\columnwidth]{Figures/vuls.png}
  \caption{Databases used by Vuls.}
	\label{fig:vuls_db}
\end{figure}

\subsubsection{Stools}

\href{https://github.com/singularityhub/stools}{Stools} combines CoreOS's ClairScanner with the Continuous Integration (Travis and
Circle) for scanning Singularity images for vulnerabilities.
Initially, ClairScanner was intented to scan Docker Containers. This tool does not fit well
to scan Singularity images because of the different image formats. Docker layers
consist of layers, whereas Singluarity images consist of a single binary file.
However, TravisCI and CircleCI are commonly used for testing code, and these
services also offer running containers. So Stools combined both the concepts.
It involves spinning a ClairScanner container during testing and building a
Singularity image, and scanning it for filesystem before the image is finalized.

\subsection{CBRAIN}

\href{http://github.com/aces/cbrain}{CBRAIN}~\cite{sherif2014cbrain} is a web portal that is
used for the processing of distributed data on various storage locations of computing
clusters. CBRAIN system deployed by Montreal Neurological Institute depends on the infrastructure
delivered by Compute Canada~\cite{das2016mni}.
It is also used by CONP to exploit services of Compute Canada. CBRAIN is a collaborative
neuroimaging research platform that is active in production since 2009. CBRAIN
provides transparent access to various distributed storage sites and computing
resources across the world. CBRAIN’s infrastructure consists of three main
layers, namely access layer, service layer, and infrastructure layer~\cite{sherif2014cbrain}. The access
layer is for CBRAIN users, and can be accessed through any modern browser or
RESTful API. The service layer consists of CBRAIN portal, which contains
metadata and databases. It provides information about users, their permissions,
resources etc. The infrastructure layer consists of data resources and computing
resources, which are connected through a network. 
CBRAIN supports Docker, Singularity, BIDS apps, and Boutiques.
CBRAIN users uses a portal
account on the cluster. Users are only able to
run pre-defined applications on the cluster through the CBRAIN portal.

%\bibliographystyle{vancouver-authoryear}
\bibliography{bibliography}


\end{document}

