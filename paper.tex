% GigaScience template
\documentclass[a4paper,num-refs]{oup-contemporary}

\journal{gigascience}


%%%% Packages %%%%
\usepackage{siunitx}
\usepackage{algpseudocode} % Algorithmic environment
\usepackage{xspace}
\usepackage{csvsimple}
\usepackage{minted} % Used for JSON highlighting
\usepackage{datatool}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{caption}
\usepackage[justification=centering]{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{adjustbox}
\usepackage{makecell}
\usepackage[flushleft]{threeparttable}

%%%% Commands %%%%
\newcommand{\todo}[1]{\color{red}\textbf{TODO:}#1\color{black}}
\newcommand{\note}[2]{\color{blue}Note: #1\color{black}}
\newcommand{\reprozip}[0]{ReproZip}
\newcommand{\TG}[1]{\color{blue}From Tristan: #1\color{black}}

\title{Vulnerability Analysis of Container Images in Neuroimaging field}
  
\begin{document}

\author[1]{Bhupinder Kaur}
\author[1]{Tristan Glatard}
\author[1]{Aiman Hanna}

\affil[1]{Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada}

\maketitle

\begin{keywords}
Containers; Security; Docker; Singularity; Neuroimaging.
\end{keywords}


\section{Introduction}

Containers, which provide operating system (OS) level virtualization, are very
popular. This is because they are very lightweight, flexible, resource-efficient,
provide fast development cycles, continuous delivery,
and cost reduction of infrastructure. OS-level virtualization gained a lot of interest when Docker was
introduced in 2013~\cite{gantikow2016providing}. However, Docker has security concerns due to which it
is not supported by High Performance
Computing (HPC) environments. As a result, Singularity came in 2016 with the goal of providing support
for HPC environments. It is used in many clusters including Compute Canada.
According to~\cite{kurtzer2017singularity}, Singularity is used in 36 research clusters.

\begin{comment}
\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{Figures/cluster_list.png}
	\caption{List of HPC clusters using Singularity~\cite{kurtzer2017singularity}.}
	\label{fig:cluster_list}
\end{figure}
\end{comment}

No doubt containers have gained a lot of popularity, however containers tightly
integrate with the host due to the sharing of the kernel, 
mounted file systems, and devices, which raises security
concerns.
They also share three main security threats with other virtualization
techniques~\cite{gantikow2016providing}.

\begin{comment}
\begin{figure}
  \centering
  \includegraphics[width=.7\columnwidth]{Figures/container.png}
  \caption{Architecture of Container-based
                Virtualization.}
  \label{fig:container-overview}
\end{figure}
\end{comment}
\textit{Privilege Escalation} A malicious attacker can break out of the container
and gain control of the host system and other containers running on the same host.

\textit{Denial-of-Service} One container may end up eating all the resources of the
host hence resulting in the starvation of the host and other containers.

\textit{Information Leak} Private data of the host and other containers could be
leaked and can be used for further attacks.


However, two features of the Linux kernel, \textit{control groups} and \textit{namespaces},
are used by containers to mitigate these threats to a certain extent. Security
of containers is still most concerning issue. According to a Forrester survey~\cite{bettini2015vulnerability}
done in January 2015, security is the
biggest concern while deploying containers.
Except web applications, containers are also popularly used for scientific computing
and data science in neuroscience. In fact, Singularity was developed for scientific applications
by keeping focus on HPC environments. This popularity of containers lead us to the
primary research question of this work: \textit{what is the current security state of
container images that are deployed on HPC clusters}.

To answer that question, we scan images that are used on Compute
Canada clusters by neuroscience field. Scanning refers to the practice of
collecting all information about the container image, investigating it
for vulnerabilities, and finally producing a
report to summarize scanning results. It is broadly categorized into
two types: static scanning and dynamic scanning. The former scanning technique
involves extracting information of an image without running it into a container,
whereas the latter approach involves launching the container from the target image, and
then scanning the running container.
Here, we focus mainly on vulnerability scanning.
\begin{comment}
Malware is a computer software that is specially designed to attack the target computer,
whereas 
\end{comment}
Vulnerability is a weakness in the developer's software that can be used
by the attacker to perform unathorized actions on the target computer.
In this paper, we report all vulnerabilities that are present in
container images, specifically used by neuroimaging field, and access their
related risks for data analysis. Particularly, we aim to answer three primary
research questions:

\textit{RQ1:} Are vulnerabilities present inside container images that are
deployed on HPC clusters?

\textit{RQ2:} Can we get rid of these vulnerabilities by updating the
images?

\textit{RQ3:} Can we get rid of these vulnerabilities by shrinking the
size of the image?

To answer those questions, we take an example of neuroscience field where
containers are used on Compute Canada HPC cluster.
The existing research work on containers focuses mainly on the security of Docker
containers.
This focus is justified by the fact that, containers expose the host's resources
(e.g., file system/ IPC) to the guest system. This feature raises a confidentiality
threat for the applications running on the same host. Previous studies evaluated
security of Docker engine ~\cite{martin2018docker, sultan2019container, combe2016docker, bui2015analysis},
and have scanned vulnerabilities on Docker hub images~\cite{Shu2017, gummaraju2015over}.
Also Singularity came up with Stools, which can be used for scanning Singularity images
for security and quality checks.
Here, we focus on the specific context of scientific data analysis on HPC clusters, taking
neuroimaging as an example.


This paper is organized as follows: in next section, we provide description
of materials and methods which includes summarizing a particular use case of
containers in neuroscience, which is used for scientific computing. It involves
usage of containers on shared HPC cluster. Additionally, in this section we
describe all the resources that are used by this use case. We also explain
scanning tools that we use for scanning container images to report
vulnerabilities. Next section of this paper is about the results. Here, we
present number and type of vulnerabilites that are present in the container images
which are used for data analysis on shared HPC clusters, and discuss how many of them are
critical vulnerabilities. Following section is about discussion of these results
where we provide more insight into the risks that are caused by these vulnerabilties
and how they can be leveraged to design attacks. Here, we also provide some such
vulnerability examples. Finally, we conclude this paper by discussing ten simple
rules that can be followed to secure container image for use in clusters.

\section{Materials and Methods}

\begin{comment}
As we are taking a particular use case of containers from
neuroscience field i.e Canadian Open Neuroscoence Platform (CONP) so  
in this section we summarize the data and tools 
that are used in CONP. CONP is a national platform for sharing neuroscience
research data and aims at creating an interactive interface for neuroscientists and
clinical neuroscience. The main goal of the CONP platform is to store, process, and
distribute massive amounts of data produced by modern neuroscience.
Here, we summarize all the resources that are
used by CONP to function.
\end{comment}

\subsection{Container Engines}

\subsubsection{Singularity}

Singularity offers mobility of compute by facilitating portable environments 
through a single image file~\cite{kurtzer2016singularity}. Once Singularity image
is created, it is hashed by using SHA256 hashing. Hence, it cannot be changed
once it is created, consequently, it can be used for reproducing the results of
scientific experiments. Main features provided by
Singularity are mobility of compute and reproducibility~\cite{kurtzer2017singularity}.
We used Singularity version $2.5.2$ in our experiments.
Users can easily access files, devices, sockets, ports of the host system from
the Singularity container. By default, Singularity bind mounts /home/\$USER, /tmp, and \$PWD
into the running container. Additional directories can be specified with \textit{--bind}
to bind mount into the container. By defaut, Singularity uses as less as possible namespaces.
However namespaces can be requested if required. Users cannot escalate privileges inside
Singularty containers. This is because Singularity do not run containers as root.
Instead, a user inside Singularity container is the same user outside the container.


\subsubsection{Docker Engine}

Docker runs a software, \textit{Docker daemon}, on the host machine.
Docker daemon runs as root, and is remotely controlled through a
UNIX socket. It is responsible for launching containers, their
isolation, and spawning shells into the containers. It is also
responsible for managing Docker images i.e \textit{pull} and \textit{push}
from image repository, building images from Dockerfiles, signing them, etc..
When a Docker container runs, the container process is spawned as a
child of this root owned daemon. As Docker users directly interact with the
Docker daemon, it is possible to force Docker daemon to escalate privileges.
If a user gets \textit{root} privileges, it introduces unthinkable security risks
for multi-tenant shared enviornments. Due to this reason, Docker is not
supported by HPC environments. However, Docker images can be imported into
Singularity and then used on HPC clusters.

\subsection{Container Image Formats}

A container image is a package that contains the application along with its
required dependencies and libraries.
Both, Docker and Singularity, have different image format. Below we provide description of both image
formats.

\subsubsection{Docker Image Format}

Docker images are organized as a series of layers stacked on top of each
other and identified by unique layer identifiers. If a layer is reused
in different images it will
have the same id across images. Each layer consists of a filesystem diff
with respect to the layer below. DockerHub uses gzip compression for
transferring layers. \begin{comment}There are two ways to create a Docker image. The
first is to use an existing Docker image as a base image and then build a
new image from that one, by making changes in the filesystem, which is
saved as a new layer of the Docker image. The second way is to build a new
Docker image from scratch.\end{comment} Docker supports several different storage drivers.
\textit{Overlay2} is the preferred storage driver used by Docker for all currently
supported Linux versions, whereas \textit{aufs} is preferred for Docker 18.06 and
older, when using Ubuntu 14.04 on kernel 3.13 as it do not support \textit{overlay2}.
Other storage drivers that are supported by Docker include \textit{devicemapper, btrfs,
zfs, and vfs}

\subsubsection{Singularity Image Format}

Singularity takes snapshot, locks, and archives the developed application,
which is known as Singularity image.
It means that Singularity image is a single immutable file that can be moved around as
any other file. This file can be checksummed, signed, and easily
used for verification purposes. Singularity containers use Squashfs file format
by default. It is read-only file system in Linux, which uses compression for files,
inodes, and directories. However, Singularity also supports two other 
formats i.e \textit{sandbox} format
(which is just a chroot
directory) and \textit{writable} format (the ext3 file system).
While publishing experimental results, authors can also publish Singularity
image along with its hash, which allow other researchers to verify results.

\subsection{Application frameworks}

We used containerized applications available in the Boutiques and BIDS Apps
frameworks used in neuroscience to run analyses on HPC clusters. 

\subsubsection{Boutiques}

Boutiques~\cite{glatard2018boutiques} is a application sharing system to
publish, integrate, and execute command-line applications across different
platforms. In Boutiques, the command-line of the application is described
through a flexible JSON descriptor pointing to a Docker or a Singularity
image where the application is installed. A set of core tools help
construct, validate, publish and execute Boutiques descriptors. Boutiques
applications are published on the Zenodo research repository.

We used the 49 Boutiques applications published on Zenodo at the time of
the writing. These applications use 23 different container images,
including 7 Singularity images and 16 Docker images.

\subsubsection{Brain Imaging Data Structure (BIDS) Apps}

BIDS apps~\cite{gorgolewski2017bids} is a framework designed to share and execute neuroimaging
analysis pipelines. It improves usability, accesibility, and reproducibility
of different applications through containerization.
Currently, there are 27 BIDS apps available and all are using different Docker images.
%\begin{figure}
%\csvreader[%
% respect all,%
%  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
%      %\caption{Baseline GF Competition Circle Track 2014}\label{tab:baselline1}
%      \begin{adjustbox}{max width=\columnwidth},
%  after reading=\end{adjustbox},
% tabular={c |c | c | c | c},
%	table head =Image & {OS Distro} & {Vulnerabilities by Anchore} & {Vulnerabilities by Clair} & {Vulnerabilities by Vuls}\\\hline,
% late after line= \\,
%	late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
%]{results.csv}{}{\csvlinetotablerow}%
%       \centering
%	\caption{Existing number of Vulnerabilities}
%\end{figure}

\begin{comment}
\subsubsection{ReproNim}

ReproNim is a Center for Reproducible Neuroimaging Computation. It is a vision
to help neuroscientists in reproducing neuroimaging research. Repronim
uses RepronIn, BrainVerse, Neuroimaging Computation Environments Manager (NICEMAN),
and NeuroBlast software tools for its
functioning. ReproIn is a software that automate acquisition and conversion
of collected MRI data to BIDS standard format with DataLad version management~\cite{kennedy2019everything}.
BrainVerse is a cross-platform software framework and collaborative desktop application
that helps in managing, tracking, and sharing information.
NICEMAN is a software system that tracks and manages available computation resources
and makes their use in a scalable and reproducible way.
Neuroblast is a service that facilitates data sharing of existing studies, and it also
helps users to search similar studies based on combination of analysis,
tasks and activation patterns. There are currently 28 different Singularity
images used by Repronim. 

\subsection{Other images}

\TG{We could also use selected images from DockerHub or SingularityHub. For
instances the ones used by AFNI or other neuroimaging tools not represented
in Boutiques or BIDS Apps. However we wouldn't be able to shrink these
images unless we identified specific command-lines to run.}

\end{comment}

\subsection{Linux Distributions}

BIDS app and Boutiques images that we took for our experiment have diverse Linux
distributions such as Ubuntu, Centos, Debian, and Alpine. In case of Ubuntu, release
can be of two types i.e regular or LTS(Long Term Support) release.
Regular release is supported only for 9 months, whereas LTS is supported for 5 years. Once LTS support
reaches End-Of-Life(EOL), Ubuntu decides whether to provide extended security support or not, which comes
in the form of Extended Security Maintenance(ESM) release.
ESM is a paid service that can be requested from Ubuntu to get security 
updates even after the EOL of a particular Ubuntu release. The ESM support period is decided by
Ubuntu. ESM and LTS releases of a particular Ubuntu distribution have different vulnerability
data in vulnerability databases.

Some Ubuntu distributions that are present inside images have already reached EOL such as 14.04 Long Term Support (LTS),
17.04, and 17.10. However, Ubuntu is providing ESM support for Ubuntu 14.04. The images in our experiment have Ubuntu 14.04 LTS so scanners should refer
to LTS release only while collecting data from vulnerability databases. If scanners refer to ESM release for data it may result
in false positives and false negatives.
Also, if these releases with EOL are used in images, there are no chances of getting updates, hence
resulting in vulnerable images. Additionally, even if ESM release is present for some EOL release it is
not feasible to use inside images. 

\subsection{Image Update Process}

If there exist vulnerabilities in the container image, then we can
run after updating the
image. Updating the image involves updating all software packages that are
inside that image. We used a bash script(\href{https://github.com/kaurbhupinder/Vulnerability-Analysis}{Github}) 
to update all images, which checks
package manager present inside the image and then according to that it
updates the image. However, this option effects the reproducibility
of the image, which means that the image cannot be used to verify research
findings of other scientists.


\subsection{Scanning tools used}

Out of the various container image scanning tools available to scan Docker images,
we selected Anchore~\cite{github_2019}
and Vuls~\cite{future-architect_2019} because these are the most mature scanning tools. To scan Singularity images
we use Stools, which is specially designed for Singularity images. This tool internally uses
Clair Scanner tool so we included ClairScanner also in our experiements to compare
performance of both the tools. So total there are three scanners for Docker images
and one scanner for Singularity images.

\subsubsection{Anchore}

Anchore is an end-to-end, open-source container security platform. Anchore
is a static
scanning tool that analyses container images and lists OS
packages, non-OS packages (Python, Java, Gem, and Npm), and files.
Anchore is a set of tools, which users can
employ for scanning container images and applying custom policies to them.
It provides visibility and transparency of the container environment.
It offers services in two ways: Anchore Engine and Anchore Engine
Command Line Interface (CLI). Anchore Engine is available as a Docker
image, which is available on Docker Hub. Anchore Engine CLI provides
command line interface in addition to Anchore Engine REST API. It can be
installed directly on the host and used to inspect images.
Anchore compares package versions, which are present inside the
image, with the vulnerability database to flag vulnerabilities.
To get vulnerability feed of various OS distribution, Anchore refers to
different sources. For example Ubuntu launchpad database is used for Ubuntu. 
\subsubsection{Vuls}

Vuls is an open-source vulnerability scanner for Linux and FreeBSD.
It is an agentless vulnerability scanner and uses various
vulnerability databases. Using dynamic scanning technique, it offers
remote and local scan. Remote scan involves setting up only one machine, to
which other target servers are connected via SSH. Local scan involves running
the scan on the target server itself. Further, Vuls offer fast scan, fast root scan,
and deep scan.
Fast scan is performed without root privileges, whereas fast root scan is
performed with root privileges. The latter also uses checkrestart utility to 
detect processes that are updated but not yet restarted because if they are not
restarted, updates are not effective. So fast root scan also detects these pro-
cesses. Both fast scan and fast root scan are performed offline without Internet
access, and put almost no load on the scan target server. Deep scan uses
root privileges for scanning, and is used to get a more detailed scan. It checks
changelogs, which puts more load on the target server.
Vuls gets data from Open Vulnerability and Assessment Language (OVAL).
The interesting point is that there is no OVAL data for Ubuntu 17.04 and 17.10 distribution,
meaning that images with these distributions are impossible to scan with Vuls.



\subsubsection{Clair Scanner}

CoreOS originally created Clair, which is a static vulnerability scanner for containers which
currently support App Container (appc) and Docker~\cite{coreos_2019}. The main goal of the
tool is to provide a transparent look of container’s security. Clair scans container images in regular
intervals, and stores metadata of vulnerabilities, after getting from configured
set of sources. Clair API can be used by clients to query its database to get
the list of vulnerabilities that a particular image has. Clair sends a notification
to alert systems that there is an updation in the vulnerability metadata. Quay
registery uses Clair internally as the security engine. However, Clair does not 
provide facility of comparing
the vulnerability list of a particular image against a whitelist~\cite{arminc_2019}. So to remove
that drawback, another tool from CoreOS, Clair Scanner can be used. It scans image, prepares the list of
vulnerabilities, compares that list against the whitelist, and flags vulnerabilities
that are not present in whitelist.
Clair Scanner refers to Ubuntu CVE tracker for getting Ubuntu vulnerability feed.
For that purpose a Docker image is maintained that contains Ubuntu CVE tracker database.
Whenever Ubuntu updated its database, this image is also updated with the required information.
We performed scanning on 2019-09-25 and for our experiments, we used a Docker image that was 
latest updated i.e with the tag 2019-09-18. So it means that Clair Scanner's database was
old by one week.

\subsubsection{Stools}

\href{https://github.com/singularityhub/stools}{Stools} combines CoreOS's Clair Scanner with the Continuous Integration (Travis and
Circle) for scanning Singularity images for vulnerabilities.
Initially, Clair Scanner was intented to scan Docker Containers. This tool does not fit well
to scan Singularity images because of the different image formats. Docker layers
consist of layers, whereas Singluarity images consist of a single binary file.
However, TravisCI and CircleCI are commonly used for testing code, and these
services also offer running containers. So Stools combined both the concepts.
It involves spinning a Clair Scanner container during testing and building a
Singularity image, and scanning it for filesystem before the image is finalized.

\begin{comment}
\subsection{CBRAIN}

\href{http://github.com/aces/cbrain}{CBRAIN}~\cite{sherif2014cbrain} is a web portal that is
used for the processing of distributed data on various storage locations of computing
clusters. CBRAIN system deployed by Montreal Neurological Institute depends on the infrastructure
delivered by Compute Canada~\cite{das2016mni}.
It is also used by CONP to exploit services of Compute Canada. CBRAIN is a collaborative
neuroimaging research platform that is active in production since 2009. CBRAIN
provides transparent access to various distributed storage sites and computing
resources across the world. CBRAIN’s infrastructure consists of three main
layers, namely access layer, service layer, and infrastructure layer~\cite{sherif2014cbrain}. The access
layer is for CBRAIN users, and can be accessed through any modern browser or
RESTful API. The service layer consists of CBRAIN portal, which contains
metadata and databases. It provides information about users, their permissions,
resources etc. The infrastructure layer consists of data resources and computing
resources, which are connected through a network. 
CBRAIN supports Docker, Singularity, BIDS apps, and Boutiques.
CBRAIN users uses a portal
account on the cluster. Users are only able to
run pre-defined applications on the cluster through the CBRAIN portal.
\end{comment}
\section{Results}

In this section, we present results of three experiments that are carried out to see
how the number of vulnerabilities vary inside images. First experiment involves scanning
these images as it is to see how vulnerable they are. For scanning we use three different scanners
to see if all are reporting same vulnerabilities or not. Second experiment involves updating
all these images and then rescanning. The last experiment involves shrinking the size of the image
meaning that removing all unnecessary packages from the image to see the effect on the number of
vulnerabilities present inside the image.

\subsection{Existing Vulnerabilities}

Figure~\ref{fig:graph1} represents the number of vulnerabilities that are present inside images.
This figure shows that as the number of packages increases in the image, the number of vulnerabilities
also get increased for Ubuntu OS distribution. The figure also infers that Alpine distribution, being the
light weight distribution, have least number of vulnerabilities, whereas Ubuntu contains highest number of
vulnerabilities. Debian contains highest number of critical vulnerabilities among Ubuntu, Alpine, and Centos.

\begin{table}
\csvreader[%
 respect all,%
  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
      \begin{adjustbox}{max width=\columnwidth},
  after reading=\end{adjustbox},
 tabular={c |c | c | c | c},
        table head =Image & {OS Distro} & {Vulnerabilities by Anchore} & {Vulnerabilities by Clair} & {Vulnerabilities by Vuls}\\\hline,
 late after line= \\,
        late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
]{results.csv}{}{\csvlinetotablerow}%
       \centering
	\caption{\label{table1}Existing number of Vulnerabilities}
\end{table}

\begin{table}
\csvreader[%
 respect all,%
  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
      \begin{adjustbox}{max width=\columnwidth},
  after reading=\end{adjustbox},
 tabular={c|c},
	table head ={Image Tag} & {Image Name}\\\hline,
 late after line= \\,
        late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
]{names.csv}{}{\csvlinetotablerow}%
       \centering
	\caption{\label{table2}Image names}
\end{table}



\begin{figure}[!htb]
        {\includegraphics[scale=2.5,width=\columnwidth]
        {Figures/vennDiagram.png}}
        \caption{\label{fig:venn} Venn Diagram representing different scanner results}
\end{figure}

\begin{figure}[!htb]
        {\includegraphics[scale=2,width=\columnwidth]
        {Figures/vulngraph4.png}}
        \caption{\label{fig:graph1} Scatterplot representing \#Packages and \#Vulnerabilities}
      \end{figure}

\subsection{Comparisons between Scanners}

Figure~\ref{table1} shows results of scanning BIDS and Boutiques images with three scanners namely Anchore,
Clair scanner and Vuls. Venn Diagram in Figure~\cite{fig:venn} summarizes this table. It is interesting to note that
Anchore reports 4453 different vulnerabilities, which is way more than both Clair and Vuls.

The number and type of vulnerabilities reported by three scanners are drastically different from each other.
The question arises why these scanners report different number and type of vulnerabilities.
How their logic differs and what exactly is making these results different than each other.

According to our investigation of these results, below are some of the reasons of
getting different results from these scanners. These reasons include bugs in scanners,
some scanners ignoring vulnerabilities in a particular package, referring to different databases,
how frequently they are updating their databases, etc. 

We have explained these differences below in detail
and have provided an example with each reason to make it clear.

Venn Diagram~\ref{fig:venn} illustrates that Anchore reports 4453 different vulnerabilities that are reported
by Vuls and Clair. Out of this 4443 vulnerabilities are present in linux-kernel-headers. These are ignored by
both Clair and Vuls.

\textbf{Linux-Kernel-Headers-} Clair Scanner and Vuls are ignoring all vulnerabilities in the Linux-kernel-headers.
4443 out of 4453 vulnerabilities difference is due to linux-kernel-headers.
For example CVE-2019-9506 present in linux-libc-dev-4.4.0-31.50 is not detected by both Vuls and Clair Scanner

\textbf{With Status as “Not-affected”-} It means these vulnerabilities are affecting Ubuntu but they are not 
affecting particular Ubuntu release that is present inside the image. The reason why its not affecting 
that release is also mentioned. For example, one reason can be that code which is creating issue is not 
present in that release etc. In other words, we can say that these are false positives by Vuls.
For example CVE-2015-2305 is not affecting package cups in Trusty.

\textbf{With status as "Ignored(reached end-of-life)"-} Some vulnerabilities have status as “ignored (reached end-of-life)”.
These vulnerabilities are "ignored" in Ubuntu 14.04 LTS as it reached end-of-life. 
However, in Ubuntu 14.04 ESM release these vulnerabilities can be present or not.
Anchore checks the last status of these vulnerabilities whether OS package was vulnerable to the cve
prior to the end-of-life. If it was vulnerable only then Anchore will report it, otherwise not.
If this kind of vulnerability is present in ESM release then Clair will report it because Clair Scanner
only refers ESM release. On the other hand, if the vulnerability
status in ESM release is "DNE", which means does not exist, then Clair Scanner will not report it. 
For example CVE-2017-9994 vulnerability. As Ubuntu LTS release is present inside the images so
Clair Scanner's reference to ESM release is wrong here.

\textbf{Vulnerabilities not present in Ubuntu 14.04 ESM release-} These vulnerabilities are not present in Ubuntu 14.04 ESM so they 
are not detected by Clair but they affect Ubuntu 14.04 LTS That’s why detected by Vuls. For example, CVE-2017-1375.

\textbf{False negatives by Clair-} Clair is missing vulnerabilities that it should detect. For example CVE-2016-9082 
is present in package cairo in Xenial release and it is not detected by Clair.

\textbf{False positives by Clair-} These vulnerabilities are not linked to Ubuntu 14.04 LTS which is 
present inside the image but Clair is showing because these vulnerabilities are present in Ubuntu 14.04 ESM and 
Clair is only referring to Ubuntu 14.04 ESM release. For example CVE-2019-1274.

\textbf{Database difference-} As we discussed earlier that Clair Scanner's database was old by one week.
                So some of the vulnerabilities were not updated yet. For example CVE-2019-5094, which
		was published on 2019-09-24, was not 
		updated in Clair Scanner's database that time. Due to which it is missed by Clair Scanner.

\textbf{Epoch bug-} There is a bug in the Anchore scanner due to which some vulnerabilities are 
		not detected by Anchore. This bug gets triggered when package’s version have epoch 
		(1:3.3.9-1ubuntu2.3)  in it. For example CVE-2018-1125 in procps package.

\textbf{with status as "Ignored (out of standard support)" bug-} There is another bug in Anchore due to 
		which it is not able to detect some vulnerabilities. Due to this bug Anchore does not detect 
		vulnerabilities which have a status as “ignored (out of standard support)” in Ubuntu 14.04 LTS. 
		But if this vulnerability is present in Ubuntu 14.04 ESM release it is detected by Clair. 
		For example CVE-2019-13565 in Ubuntu 14.04.


\textbf{False Negatives by Vuls-} Vuls is missing some of the vulnerabilities that it should detect. 
		For example CVE-2019-5094

\textbf{Rejected CVEs-} There are some CVE that are rejected because they are duplicate copies of another CVEs. 
	So Anchore is not reporting those rejected CVEs but Vuls is reporting those. For example CVE-2017-13753

\subsection{Effect Of Update}

The next experiment involves updating all these images and then rescanning them to see how the number of
vulnerabilities drop inside them. We used a \textit{bash} script to update these images. This script is
present in our github repository \href{https://github.com/kaurbhupinder/Risk-to-Clusters-Paper}
{https://github.com/kaurbhupinder/Risk-to-Clusters-Paper}. This script 
will find package manager inside the image and then update the image according the package manager it finds.
When these images are rescanned after updation, results changed drastically. However, there are still
vulnerabilities reported by these scanners but there are no fixes available for these vulnerabilities
till date so there is nothing that can be done to remove these vulnerabilties. There are only two
options, either you accept those vulnerabilities and use that image, or you discard that image.
So one thing is clear here that even if we keep our images up to date there will be still some
vulnerabilities that we have to face.
Figure~\ref{fig:graph2}shows number of vulnerabilities that are detected by Anchore after updating these images.

\begin{figure}[!htb]
        {\includegraphics[width=\columnwidth]
        {Figures/aferupdatewithpackage.png}}
        \caption{\label{fig:graph2} Scatterplot representing difference in number of vulnerabilities before and 
	after update of image}
      \end{figure}
\subsection{Effect Of Size Reduction}

\bibliography{bibliography}


\end{document}

