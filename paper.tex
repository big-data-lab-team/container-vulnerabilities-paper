% GigaScience template
\documentclass[a4paper,num-refs]{oup-contemporary}

\journal{gigascience}


%%%% Packages %%%%
\usepackage{siunitx}
\usepackage{algpseudocode} % Algorithmic environment
\usepackage{xspace}
\usepackage{csvsimple}
\usepackage{minted} % Used for JSON highlighting
\usepackage{datatool}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{caption}
\usepackage[justification=centering]{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{adjustbox}
\usepackage{makecell}
\usepackage[flushleft]{threeparttable}

%%%% Commands %%%%
\newcommand{\todo}[1]{\color{red}\textbf{TODO:}#1\color{black}}
\newcommand{\note}[2]{\color{blue}Note: #1\color{black}}
\newcommand{\reprozip}[0]{ReproZip}
\newcommand{\rom}[1]{\lowercase\expandafter{\romannumeral #1\relax}}
\newcommand{\TG}[1]{\color{blue}From Tristan: #1\color{black}}

\title{Vulnerability Analysis of Container Images in Neuroimaging}
  
\begin{document}

\author[1]{Bhupinder Kaur}
\author[1]{Aiman Hanna}
\author[1]{Tristan Glatard}

\affil[1]{Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada}

\maketitle

\begin{keywords}
Containers; Security; Docker; Singularity; Neuroimaging.
\end{keywords}


\section{Introduction}

Containers, which provide operating system (OS) level virtualization, are very
popular. This is because they are very lightweight, flexible, resource-efficient,
provide fast development cycles, continuous delivery,
and cost reduction of infrastructure. OS-level virtualization gained a lot of interest when Docker was
introduced in 2013~\cite{gantikow2016providing}. However, Docker has security concerns due to which it
is not supported by High Performance
Computing (HPC) environments. As a result, Singularity came in 2016 with the goal of providing support
for HPC environments. It is used in many clusters including Compute Canada.
According to~\cite{kurtzer2017singularity}, Singularity is used in 36 research clusters.

\begin{comment}
\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{Figures/cluster_list.png}
	\caption{List of HPC clusters using Singularity~\cite{kurtzer2017singularity}.}
	\label{fig:cluster_list}
\end{figure}
\end{comment}

No doubt containers have gained a lot of popularity, however containers tightly
integrate with the host due to the sharing of the kernel, 
mounted file systems, and devices, which raises security
concerns.
They also share three main security threats with other virtualization
techniques~\cite{gantikow2016providing}.

\begin{comment}
\begin{figure}
  \centering
  \includegraphics[width=.7\columnwidth]{Figures/container.png}
  \caption{Architecture of Container-based
                Virtualization.}
  \label{fig:container-overview}
\end{figure}
\end{comment}
\textit{Privilege Escalation} A malicious attacker can break out of the container
and gain control of the host system and other containers running on the same host.

\textit{Denial-of-Service} One container may end up eating all the resources of the
host hence resulting in the starvation of the host and other containers.

\textit{Information Leak} Private data of the host and other containers could be
leaked and can be used for further attacks.


However, two features of the Linux kernel, \textit{control groups} and \textit{namespaces},
are used by containers to mitigate these threats to a certain extent. Security
of containers is still most concerning issue. According to a Forrester survey~\cite{bettini2015vulnerability}
done in January 2015, security is the
biggest concern while deploying containers.
Except web applications, containers are also popularly used for scientific computing
and data science in neuroscience. In fact, Singularity was developed for scientific applications
by keeping focus on HPC environments. This popularity of containers lead us to the
primary research question of this work: \textit{what is the current security state of
container images that are deployed on HPC clusters}.

To answer that question, we scan images that are used on Compute
Canada clusters by neuroscience field. Scanning refers to the practice of
collecting all information about the container image, investigating it
for vulnerabilities, and finally producing a
report to summarize scanning results. It is broadly categorized into
two types: static scanning and dynamic scanning. The former scanning technique
involves extracting information of an image without running it into a container,
whereas the latter approach involves launching the container from the target image, and
then scanning the running container.
Here, we focus mainly on vulnerability scanning.
\begin{comment}
Malware is a computer software that is specially designed to attack the target computer,
whereas 
\end{comment}
Vulnerability is a weakness in the developer's software that can be used
by the attacker to perform unathorized actions on the target computer.
In this paper, we report all vulnerabilities that are present in
container images, specifically used by neuroimaging field, and access their
related risks for data analysis. Particularly, we aim to answer three primary
research questions:

\textit{RQ1:} Are vulnerabilities present inside container images that are
deployed on HPC clusters?

\textit{RQ2:} Can we get rid of these vulnerabilities by updating the
images?

\textit{RQ3:} Can we get rid of these vulnerabilities by shrinking the
size of the image?

To answer those questions, we take an example of neuroscience field where
containers are used on Compute Canada HPC cluster.
The existing research work on containers focuses mainly on the security of Docker
containers.
This focus is justified by the fact that, containers expose the host's resources
(e.g., file system/ IPC) to the guest system. This feature raises a confidentiality
threat for the applications running on the same host. Previous studies evaluated
security of Docker engine ~\cite{martin2018docker, sultan2019container, combe2016docker, bui2015analysis},
and have scanned vulnerabilities on Docker hub images~\cite{Shu2017, gummaraju2015over}.
Also Singularity came up with Stools, which can be used for scanning Singularity images
for security and quality checks.
Here, we focus on the specific context of scientific data analysis on HPC clusters, taking
neuroimaging as an example.


This paper is organized as follows: in next section, we provide description
of materials and methods which includes summarizing a particular use case of
containers in neuroscience, which is used for scientific computing. It involves
usage of containers on shared HPC cluster. Additionally, in this section we
describe all the resources that are used by this use case. We also explain
scanning tools that we use for scanning container images to report
vulnerabilities. Next section of this paper is about the results. Here, we
present number and type of vulnerabilites that are present in the container images
which are used for data analysis on shared HPC clusters, and discuss how many of them are
critical vulnerabilities. Following section is about discussion of these results
where we provide more insight into the risks that are caused by these vulnerabilties
and how they can be leveraged to design attacks. Here, we also provide some such
vulnerability examples. Finally, we conclude this paper by discussing ten simple
rules that can be followed to secure container image for use in clusters.

\section{Materials and Methods}

This study involves three image scanning experiments.
The first experiment scans the images as is to report the existing vulnerabilities
inside the images. The scan report of
these images shows a large number of existing vulnerabilities which may pose
a potential security risk. These vulnerabilities exist due to the outdated
packages that are present inside images. So, the next step is to
take the necessary steps to improve security in the images. Therefore, there exist
two possible solutions.
The first one involves updating
all these images and then rescanning them, which constitutes the next experiment of our study. The second one
involves shrinking the size of the image
meaning that removing all unnecessary packages from the image to see the effect on the number of
vulnerabilities present inside the image, which will be presented as our third experiment.

We first
introduce two container tools used in our experiments: Docker and
Singularity and their image formats. Then we describe Boutiques and BIDS application frameworks
from where we took containerized applications for our study. 
Later, this section
presents two scanning techniques followed by a description of image scanners used.
In this study, we used three different image scanners because they
use different scanning techniques and/or refer to different vulnerability sources.
The images used in our study have different Linux distributions/releases, which have
different vulnerability data. Therefore, in the last, this section presents a
description of these varying Linux distributions/releases and their
vulnerability databases.


\begin{comment}
As we are taking a particular use case of containers from
neuroscience field i.e Canadian Open Neuroscoence Platform (CONP) so  
in this section we summarize the data and tools 
that are used in CONP. CONP is a national platform for sharing neuroscience
research data and aims at creating an interactive interface for neuroscientists and
clinical neuroscience. The main goal of the CONP platform is to store, process, and
distribute massive amounts of data produced by modern neuroscience.
Here, we summarize all the resources that are
used by CONP to function.
\end{comment}

\subsection{Container Tools}

Container tools are capable of packing and running an application in an isolated environment that have
the application's dependencies,
required libraries and configuration files for the
application to function properly.

\subsubsection{Docker}

Docker containers are managed by the Docker engine, which is a client-server application, and
is also known as Docker Daemon.

\begin{comment}
consists of the following three main components: 

\textit{Docker Daemon:} It acts as a server. It is
a long-running process that manages all Docker images, containers, storage volumes, and networks.

\textit{REST API:} It acts as an interface between the server and the client, and is an API which is used by the applications
to talk to the \textit{Docker Daemon}.

\textit{Client:} It is a Command Line Interface (CLI) client which is used to interact with the \textit{Docker Daemon}.
convert english to punjabi
\end{comment}
%Docker runs a software, \textit{Docker daemon}, on the host machine.
Docker daemon runs as root and is remotely controlled through a
UNIX socket. It is responsible for launching and managing containers,
consequently, when a container runs, the container is spawned as a
child process of this root-owned daemon.

\begin{comment}
It is responsible for launching containers, their
isolation, and spawning shells into the containers. It is also
responsible for managing Docker images i.e \textit{pull} and \textit{push}
from image repository, building images from Dockerfiles, signing them, etc.
When a Docker container runs, the container process is spawned as a
child of this root owned daemon. 
\end{comment}
As Docker users directly interact with the
Docker daemon through Command Line Interface (CLI) i.e \textit{docker} command, it is possible to force Docker daemon to escalate privileges.
If a user gets root privileges, it
introduces unthinkable security risks for multi-tenant shared
environments. Due to this reason, Docker is not supported by
HPC environments.

Docker images are organized as a series of layers stacked on top of each
other and identified by unique layer identifiers. If a layer is reused
in different images it will
have the same id across images. Each layer consists of a filesystem diff
with respect to the layer below.

\subsubsection{Singularity}

Singularity is another tool for packing and running applications in containers. 
In our experiments, we used $2.5.2$ Singularity version. In contrast to Docker,
Singularity does not run containers as root. Consequently, users cannot escalate
privileges in Singularity containers making it suitable for HPC environments.

On the other hand, a Singularity image is a single immutable file and
does not contain layers.
Once a Singularity image is created, it cannot be changed, consequently,
it can be used for reproducing the results of scientific
experiments.

\begin{comment}
Singularity offers mobility of compute by facilitating portable environments 
through a single image file~\cite{kurtzer2017singularity}. Once Singularity image
is created, it is hashed using SHA-256. Hence, it cannot be changed
once it is created, consequently, it can be used for reproducing the results of
scientific experiments. Main features provided by
Singularity are mobility of compute and reproducibility~\cite{kurtzer2017singularity}.
We used Singularity version $2.5.2$ in our experiments.
Users can easily access files, devices, sockets, ports of the host system from
the Singularity container. By default, Singularity bind mounts /home/\$USER, /tmp, and \$PWD
into the running container. Additional directories can be specified with \textit{--bind}
to bind mount into the container. By defaut, Singularity uses as less as possible namespaces.
However namespaces can be requested if required. Users cannot escalate privileges inside
Singularty containers. This is because Singularity do not run containers as root.
Instead, a user inside Singularity container is the same user outside the container.

\subsection{Container Image Formats}

A container image is a package that contains an application along with its
required dependencies and libraries.
Both, Docker and Singularity, have different image formats. Below we provide a description of both image
formats.

\subsubsection{Docker Image Format}

Docker images are organized as a series of layers stacked on top of each
other and identified by unique layer identifiers. If a layer is reused
in different images it will
have the same id across images. Each layer consists of a filesystem diff
with respect to the layer below. 
DockerHub uses gzip compression for
transferring layers.There are two ways to create a Docker image. The
first is to use an existing Docker image as a base image and then build a
new image from that one, by making changes in the filesystem, which is
saved as a new layer of the Docker image. The second way is to build a new
Docker image from scratch.Docker supports several different storage drivers.
\textit{Overlay2} is the preferred storage driver used by Docker for all currently
supported Linux versions, whereas \textit{aufs} is preferred for Docker 18.06 and
older, when using Ubuntu 14.04 on kernel 3.13 as it do not support \textit{overlay2}.
Other storage drivers that are supported by Docker include \textit{devicemapper, btrfs,
zfs, and vfs}

\subsubsection{Singularity Image Format}

On the other hand, a Singularity image is a single immutable file and 
does not contain layers.
Once a Singularity image is created, it cannot be changed, consequently,
it can be used for reproducing the results of scientific
experiments.
Singularity takes snapshot, locks, and archives the developed application,
which is known as Singularity image.
It means that Singularity image is a single immutable file that can be moved around as
any other file. This file can be checksummed, signed, and easily
used for verification purposes. Singularity containers use Squashfs file format
by default. It is read-only file system in Linux, which uses compression for files,
inodes, and directories. However, Singularity also supports two other 
formats i.e \textit{sandbox} format
(which is just a chroot
directory) and \textit{writable} format (the ext3 file system).
While publishing experimental results, authors can also publish Singularity
image along with its hash, which allow other researchers to verify results.
\end{comment}
\subsection{Application frameworks}

We used containerized applications available in the Boutiques and BIDS Apps
frameworks used in neuroscience to run analyses on HPC clusters. 

\subsubsection{Brain Imaging Data Structure (BIDS) Apps}

BIDS apps~\cite{gorgolewski2017bids} is a framework designed to share and execute neuroimaging
analysis pipelines. It improves usability, accesibility, and reproducibility
of different applications through containerization.
At the time of this study, there were 27 BIDS apps available and all are using different Docker images.
Out of these 27 images, we used 26 images for our experiments because one of them was not available
on the Docker hub.

\subsubsection{Boutiques}

Boutiques~\cite{glatard2018boutiques} is an application sharing system to
publish, integrate, and execute command-line applications across different
platforms. In Boutiques, the command-line of the application is described
through a flexible JSON descriptor pointing to a Docker or a Singularity
image where the application is installed. A set of core tools help
construct, validate, publish and execute Boutiques descriptors. Boutiques
applications are published on the Zenodo research repository.

We used the 49 Boutiques applications published on Zenodo at the time of
the writing. These applications use 23 different container images. Out of these images,
3 images are not found and 2 images were already included in BIDS images.
Therefore we are left with a total 18 Boutiques images which include 6
Singularity images and 12 Docker images.


\subsubsection{Brain Imaging Data Structure (BIDS) Apps}

BIDS apps~\cite{gorgolewski2017bids} is a framework designed to share and execute neuroimaging
analysis pipelines. It improves usability, accesibility, and reproducibility
of different applications through containerization.
At the time of this study, there were 27 BIDS apps available and all are using different Docker images.
Out of these 27 images, we used 26 images for our experiments because the QAP bids app was not available
on Docker hub.

So we have a total 38 Docker images from both BIDS Apps and Boutiques.
	Table~\ref{table1} displays the names of all the images that we took in our experiments.
%\begin{figure}
%\csvreader[%
% respect all,%
%  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
%      %\caption{Baseline GF Competition Circle Track 2014}\label{tab:baselline1}
%      \begin{adjustbox}{max width=\columnwidth},
%  after reading=\end{adjustbox},
% tabular={c |c | c | c | c},
%	table head =Image & {OS Distro} & {Vulnerabilities by Anchore} & {Vulnerabilities by Clair} & {Vulnerabilities by Vuls}\\\hline,
% late after line= \\,
%	late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
%]{results.csv}{}{\csvlinetotablerow}%
%       \centering
%	\caption{Existing number of Vulnerabilities}
%\end{figure}

\begin{comment}
\subsubsection{ReproNim}

ReproNim is a Center for Reproducible Neuroimaging Computation. It is a vision
to help neuroscientists in reproducing neuroimaging research. Repronim
uses RepronIn, BrainVerse, Neuroimaging Computation Environments Manager (NICEMAN),
and NeuroBlast software tools for its
functioning. ReproIn is a software that automate acquisition and conversion
of collected MRI data to BIDS standard format with DataLad version management~\cite{kennedy2019everything}.
BrainVerse is a cross-platform software framework and collaborative desktop application
that helps in managing, tracking, and sharing information.
NICEMAN is a software system that tracks and manages available computation resources
and makes their use in a scalable and reproducible way.
Neuroblast is a service that facilitates data sharing of existing studies, and it also
helps users to search similar studies based on combination of analysis,
tasks and activation patterns. There are currently 28 different Singularity
images used by Repronim. 

\subsection{Other images}

\TG{We could also use selected images from DockerHub or SingularityHub. For
instances the ones used by AFNI or other neuroimaging tools not represented
in Boutiques or BIDS Apps. However we wouldn't be able to shrink these
images unless we identified specific command-lines to run.}

\end{comment}


\subsection{Scanning Images}

Scanning an image means looking into the image, collecting all the information about the image, and
finally, using this information to detect vulnerabilities present inside the image.
Scanning can be broadly categorized into two types: \rom{1}) Static Scanning and \rom{2})
Dynamic Scanning.
In Static scanning, an image is scanned without running it into a container. In respect to that,
different image features are extracted like installed packages, their versions, files, etc.
On the other hand, Dynamic scanning involves running a container from the image and then scanning the
dynamic behavior of the image.

\subsubsection{Scanning tools used}

\begin{comment}
Out of the various container image scanning tools available to scan Docker images,
we selected Anchore~\cite{github_2019}
and Vuls~\cite{future-architect_2019} because these are the most mature scanning tools. To scan Singularity images
we use Stools, which is specially designed for Singularity images. This tool internally uses
Clair Scanner tool so we included ClairScanner also in our experiements to compare
performance of both the tools. So total there are three scanners for Docker images
and one scanner for Singularity images.
\end{comment}

We used three scanners namely Anchore~\cite{github_2019}, Vuls~\cite{future-architect_2019}, and
Clair Scanner~\cite{arminc_2019} for scanning Docker images because these are the most
mature scanners. Out of these scanners, only Vuls uses dynamic scanning and the remaining two
are static scanners.
Also, we froze vulnerability databases for these scanners on September 25, 2019, and scanned
all images to avoid getting different results due to the differences in the scanner's database.
Lastly, for scanning Singularity images, we used Stools.

\subsubsection{Anchore}

Anchore is an end-to-end, open-source container security platform. Anchore
is a static
scanning tool that analyses container images and lists OS
packages, non-OS packages (Python, Java, Gem, and Npm), and files.
\begin{comment}
Anchore is a set of tools, which users can
employ for scanning container images and applying custom policies to them.
It provides visibility and transparency of the container environment.
\end{comment}
Anchore Engine can be used in two ways: through Docker image or Anchore
Command Line Interface (CLI).
\begin{comment}
Anchore offers services in two ways: Anchore Engine and Anchore
Command Line Interface (CLI). Anchore Engine is available as a Docker
image, which is available on Docker Hub. Anchore Engine CLI provides
command line interface in addition to Anchore Engine REST API. 
\end{comment}
It can be
installed directly on the host and used to inspect images.
In our experiments, we used a Docker image to get Anchore Engine version 0.5.0 and Engine Database
version 0.0.11.

Anchore compares package versions, which are present inside the
image, with the vulnerability database to flag vulnerabilities.
To get a vulnerability feed of various OS distribution, Anchore refers to
different sources. For example, the Ubuntu launchpad database is used for Ubuntu.
In Ubuntu launchpad database, for a given CVE, there is an entry for all ubuntu releases.
Ubuntu releases are listed with the package name
in which vulnerability exists and are entitled a status
(\href{https://git.launchpad.net/ubuntu-cve-tracker/plain/README}{https://git.launchpad.net/ubuntu-cve-tracker/plain/README}), which is
encoded in the following form:
\newline \\
\noindent <release>\_<source-package>: <status> (<version/notes>) \\
\newline\\
The status can be any one of the following:

\textbf{DNE:} It means 'Does Not Exist'. The package (inside the given release) does not exist in the
		archive.

\textbf{needs-triage:} The vulnerability of this package (inside the given release)
		is not known. It needs to be evaluated.  (No version/notes)

\textbf{not-affected:} The package (inside the given release), while related to the
		CVE in some way, is not affected by the issue. Notes should
		provide detailed information if needed. For e.g
		"not-affected (1.14.6-1.1)" indicates that this specific
		package version in the given release is not affected.

\textbf{needed:} The package (inside the given release) is vulnerable to the
		CVE and needs to be fixed.

\textbf{active:} The package (inside the given release) is vulnerable to the
		CVE, needs fixing, and is actively being worked on.

\textbf{ignored:} The package (inside the given release), while related to the
		CVE in some way, is being ignored for some reason.  The
		notes should provide that reason. For e.g "ignored (reached end-of-life)".
		This means that this given Ubuntu release already reached
		end-of-life so this CVE is ignored by Ubuntu. However, if there
		is extended security support for this release then this
		CVE will be handled in ESM release.

\textbf{pending:} The package (inside the given release) is vulnerable and
                  has been fixed but an update has not been yet uploaded or
		  published. The "version" indicates the package version 
		  that contains the fix.

\textbf{deferred:} The package (inside the given release) is vulnerable, but 
                   its fix has been deferred for some reason. The notes
		   should provide further details. If a date is mentioned eg
		   "deferred (2015-02-02)" this date specifies the date when
		   the CVE was deferred.

\textbf{released:} The package (inside the given release) was vulnerable, but
		an update has been already uploaded and published. The package version
		is also mentioned. For e.g "released (1.2.3)"
		specifies the package version in which the fix first appeared.

\textbf{released-esm:} The package (inside the given release) was vulnerable and
		an update has been already uploaded and published. However,
		this update is published in the Ubuntu ESM release only and not in LTS.
		The fixed version of such packages is appended by
		+esmN or ~esmN, indicating that this package version is available
		only via ESM.

Figure~\ref{example} illustrates how the information of a CVE is represented
in the Ubuntu launchpad database.

\begin{figure}[H]
	\fbox{{\includegraphics[scale=2.5,width=\columnwidth]
	{Figures/vulnExample2.png}}}
        \caption{\label{example} Representation of a CVE in Ubuntu Launchpad}
\end{figure}



\subsubsection{Vuls}

Vuls is an open-source vulnerability scanner for Linux and FreeBSD.
Using a dynamic scanning technique, it offers
remote and local scans. The remote scan involves setting up only one machine, to
which other target servers are connected via SSH. Local scan involves running
the scan on the target server itself. Further, Vuls offer a fast scan, fast root scan,
and deep scan.
The Fast scan is performed without root privileges, whereas a fast root scan is
performed with root privileges. The latter also uses checkrestart utility to 
detect processes that are updated but not yet restarted because if they are not
restarted, updates are not effective. So fast root scan also detects these
processes. Both fast scan and fast root scan are performed offline without Internet
access, and put almost no load on the scan target server. The Deep scan uses
root privileges for scanning and is used to get a more detailed scan. It checks
changelogs, which puts more load on the target server.
Vuls gets data from Open Vulnerability and Assessment Language (OVAL).

The interesting point is that there is no OVAL data for Ubuntu 17.04 and 17.10 distribution,
meaning that images with these distributions are impossible to scan with Vuls.



\subsubsection{Clair Scanner}

CoreOS originally created Clair, a static vulnerability scanner for containers. 
\begin{comment}
The main goal of the
tool is to provide a transparent look of container’s security. Clair scans container images in regular
intervals, and stores metadata of vulnerabilities, after getting from configured
set of sources. 
\end{comment}	
Clair API can be used by clients to query its database to get
the list of vulnerabilities that a particular image has. Clair sends a notification
to alert the systems if there is an update in the vulnerability metadata. Quay.io, which
is a registry to store images privately, uses Clair internally as the security engine. However, Clair does not 
provide the facility for comparing
the vulnerability list of a particular image against a whitelist of vulnerabilities that you
want to ignore~\cite{arminc_2019}. 
So, to remove
that drawback, another tool from CoreOS, Clair Scanner can be used. It scans the image, prepares the list of
vulnerabilities, compares that list against the whitelist, and flags vulnerabilities
that are not present in the whitelist.
Clair Scanner refers to the Ubuntu CVE tracker for getting Ubuntu vulnerability feed.
For that purpose, a Docker image is maintained that contains the Ubuntu CVE tracker database.
Whenever Ubuntu updated its database, this image is also updated with the required information.

We performed scanning on 2019-09-25 and for our experiments, we used a Docker image that was 
latest updated i.e with the tag 2019-09-18. So it means that Clair Scanner's database was already
old by one week.


\subsubsection{Stools}

\href{https://github.com/singularityhub/stools}{Stools} combines CoreOS's Clair Scanner with Continuous Integration (CI)
for scanning Singularity images for vulnerabilities.
Initially, Clair Scanner was intended to scan Docker Containers. This tool does not fit well
to scan Singularity images because of the different image formats.
However, TravisCI and CircleCI are commonly used for testing code, and these
services also offer running containers. So Stools combined both the concepts.
It involves spinning a Clair Scanner container during testing and building a
Singularity image, and scanning it for filesystem before the image is finalized.

In our experiments, we used a Docker image (\href{https://hub.docker.com/r/vanessa/stools-clair}{vanessa/stools-clair:v3.2.1})
for scanning and followed the steps mentioned in (\href{https://github.com/singularityhub/stools}{Stools Github})

\subsection{Linux Distributions and Vulnerability Databases}

BIDS app and Boutiques images that we took for our experiments have diverse Linux
distributions such as Ubuntu, Centos, Debian, and Alpine. In the case of Ubuntu, release
can be of two types: regular or LTS (Long Term Support).
Regular release is supported only for 9 months, whereas LTS is supported for 5 years. Once LTS support
reaches End-Of-Life (EOL), Ubuntu decides whether to provide extended security support or not, which comes
in the form of Extended Security Maintenance (ESM) release.
ESM is a paid service that can be requested from Ubuntu to get security 
updates even after the EOL of a particular Ubuntu release. The ESM support period is decided by
Ubuntu. ESM and LTS releases of a particular Ubuntu distribution have different vulnerability
data in vulnerability databases because after EOL of a release, a vulnerability is fixed only in packages of ESM, however, it still
exists in LTS.

Ubuntu has ended support for some releases such as 14.04 LTS,
17.04, and 17.10, which means they have reached EOL. However, Ubuntu is providing optional extended support for Ubuntu 14.04.
To use this extended support, users have to buy ESM release for Ubuntu 14.04.
The images in our experiments have Ubuntu 14.04 LTS so scanners should refer
to LTS release only while collecting data from vulnerability databases. If scanners refer to ESM release for data it may result
in false positives and false negatives.
Also, if ubuntu releases with ended support are used in images, there are no chances of getting updates, hence
resulting in vulnerable images. Additionally, even if extended security is provided for some releases by Ubuntu, it is
not feasible to use it inside images because it is a paid service. 

\subsection{Image Update Process}

If there exist vulnerabilities in the container image, then we can
run after updating the
image. Updating the image involves updating all software packages that are
inside that image. We used a bash script (\href{https://github.com/kaurbhupinder/Vulnerability-Analysis}{Github}) 
to update all images, which checks the
package manager present inside the image and then according to that it
updates the image. However, this option affects the reproducibility
of the image, which means that the image cannot be used to verify the research
findings of other scientists.

\begin{comment}
\subsection{CBRAIN}

\href{http://github.com/aces/cbrain}{CBRAIN}~\cite{sherif2014cbrain} is a web portal that is
used for the processing of distributed data on various storage locations of computing
clusters. CBRAIN system deployed by Montreal Neurological Institute depends on the infrastructure
delivered by Compute Canada~\cite{das2016mni}.
It is also used by CONP to exploit services of Compute Canada. CBRAIN is a collaborative
neuroimaging research platform that is active in production since 2009. CBRAIN
provides transparent access to various distributed storage sites and computing
resources across the world. CBRAIN’s infrastructure consists of three main
layers, namely access layer, service layer, and infrastructure layer~\cite{sherif2014cbrain}. The access
layer is for CBRAIN users, and can be accessed through any modern browser or
RESTful API. The service layer consists of CBRAIN portal, which contains
metadata and databases. It provides information about users, their permissions,
resources etc. The infrastructure layer consists of data resources and computing
resources, which are connected through a network. 
CBRAIN supports Docker, Singularity, BIDS apps, and Boutiques.
CBRAIN users uses a portal
account on the cluster. Users are only able to
run pre-defined applications on the cluster through the CBRAIN portal.
\end{comment}
\section{Results}

In this section,
we first discuss the existing vulnerabilities in the images and compare
results of the three scanners. Then we discuss the effect of the update on the
existing vulnerabilities and lastly, this section presents the effect of image size reduction on the
vulnerabilities.

\subsection{Existing Vulnerabilities}

Figure~\ref{fig:venn} illustrates the number of vulnerabilities detected by scanners. The
overlapping regions of the Venn diagram show the number of common vulnerabilities detected by either two or
three scanners. In total 10691 vulnerabilities are detected by three scanners.
There are also vulnerabilities that are detected only by one scanner.

Figure~\ref{fig:graph1} gives more image-specific information.
It represents the number of vulnerabilities that are present inside images.
The overall trend of the Figure shows that as the number of packages increases in the image, the number of vulnerabilities
also get increased.
The figure also infers that Alpine distribution, being the
lightweight distribution, have the least number of vulnerabilities, whereas Ubuntu contains highest number of
vulnerabilities. Debian and Centos contain a higher number of critical vulnerabilities than Ubuntu and Alpine.

\begin{table*}
\csvreader[%
 respect all,%
  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
      \begin{adjustbox}{max width=\textwidth},
  after reading=\end{adjustbox},
 tabular={c |c | c | c | c |c},
	table head =Image Labels &{Image names} &{OS Distro} & {Vulnerabilities by Anchore} & {Vulnerabilities by Clair} & {Vulnerabilities by Vuls}\\\hline,
 late after line= \\,
        late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
]{results.csv}{}{\csvlinetotablerow}%
       \centering
	\caption{\label{table1}Existing number of Vulnerabilities}
\end{table*}

\begin{comment}
\begin{table}
\csvreader[%
 respect all,%
  before reading=\footnotesize\sisetup{round-mode=places,round-precision=2,round-integer-to-decimal}
      \begin{adjustbox}{max width=\columnwidth},
  after reading=\end{adjustbox},
 tabular={c|c},
	table head ={Image Tag} & {Image Name}\\\hline,
 late after line= \\,
        late after last line=\\\hline %\multicolumn{5}{c}{Total Score: 1481}
]{names.csv}{}{\csvlinetotablerow}%
       \centering
	\caption{\label{table2}Image names}
\end{table}
\end{comment}


\begin{figure}[H]
        {\includegraphics[scale=2.5,width=\columnwidth]
        {Figures/vennDiagram.pdf}}
        \caption{\label{fig:venn} Venn Diagram representing different scanner results}
\end{figure}

\begin{figure*}[!htb]
	{\includegraphics[scale=1.5,width=\textwidth]
	{Figures/vulngraph.pdf}}
        \caption{\label{fig:graph1} Scatterplot representing \#Packages and \#Vulnerabilities}
      \end{figure*}

\subsection{Comparisons between Scanners}

Table~\ref{table1} compares the results of scanning images with the three scanners.
Venn Diagram in Figure~\ref{fig:venn} summarizes this table. 

When we add all regions of Venn diagram
we get total 20050 vulnerabilities in Bids and Boutiques images.
It is interesting to note that out of these vulnerabilities, 4453 vulnerabilities are only
reported by Anchore, 673 only reported by Clair, and 325 only detected by Vuls.

The number and type of vulnerabilities reported by the three scanners are drastically different from each other.
The question arises why these scanners report different numbers and types of vulnerabilities.
How their logic differs and what exactly is making these results different than each other.

According to our investigation of these results, below are some of the reasons for
getting different results from these scanners. These reasons include bugs in scanners,
some scanners ignoring vulnerabilities in a particular package, referring to different databases,
how frequently they are updating their databases, etc. 

We have explained these differences below in detail
and have provided an example with each reason to make it clear.

\begin{comment}
Venn Diagram~\ref{fig:venn} illustrates that Anchore reports 4453 different vulnerabilities that are reported
by Vuls and Clair. Out of this 4443 vulnerabilities are present in linux-kernel-headers. These are ignored by
both Clair and Vuls.
\end{comment}

\textbf{Linux-Kernel-Headers:} Clair Scanner and Vuls are ignoring all vulnerabilities in the Linux-kernel-headers,
whereas Anchore reports them.
4443 out of 4453 vulnerabilities that are only reported by Anchore are present in Linux-kernel-headers.
For example CVE-2019-9506 present in Linux-libc-dev-4.4.0-31.50, which is reported by Anchore, is not
detected by both Vuls and Clair Scanner.
Linux-kernel-headers are the headers files that only provide function names, its parameters, and its
return type.
The actual source code of these functions is present in the Linux kernel and not inside the image.
So, vulnerability detection in header files
is irrelevant in this case.

\textbf{CVEs with Status as “Not-affected”:} Vuls is reporting vulnerabilities with status
as "not-affected". So it means Linux distribution which is inside the image is not affected
by the particular CVE. However, it is reported by Vuls. In other words, we can say that
these are false positives by Vuls.
For example, we scanned an image having the Trusty release in it and Vuls is reporting CVE-2015-2305
in the package Cups. However, if we check the vulnerability database, package Cups in Trusty is not
is not affected by this CVE.

\textbf{With CVE status as "Ignored (reached end-of-life)":}
Some vulnerabilities are "ignored" in Ubuntu 14.04 LTS as it reached end-of-life. 
However, in Ubuntu 14.04 ESM release these vulnerabilities may or may not be present.
Anchore checks the last status of these vulnerabilities whether the package was vulnerable to the CVE
prior to the end-of-life. If it was vulnerable only then Anchore will report it, otherwise not.
If this kind of vulnerability is present in ESM release then Clair Scanner will report it because Clair Scanner
only refers to ESM release. On the other hand, if the vulnerability
status in ESM release is "DNE" (Does Not Exist), then Clair Scanner will not report it. 
For example CVE-2017-9994 vulnerability in Libav package is ignored in Trusty LTS release due to end-of-life.
so it is not reported by Anchore. Whereas, this vulnerability has status as "DNE" in Trusty ESM
release so Clair Scanner also does not report it. As Ubuntu 14.04 LTS release is present inside the images still
Clair Scanner is referring to Ubuntu 14.04 ESM release vulnerability database.

\textbf{Vulnerabilities not present in Ubuntu 14.04 ESM release:} These vulnerabilities are not present in Ubuntu 14.04 ESM so they 
are not detected by Clair Scanner but they affect Ubuntu 14.04 LTS hence detected by Vuls. For example, CVE-2017-1375.

\textbf{False negatives by Clair:} Clair is missing vulnerabilities that it should detect. For example, CVE-2016-9082 
is present in package Cairo in Xenial release and it is not detected by Clair.

\textbf{False positives by Clair:} These vulnerabilities are not linked to Ubuntu 14.04 LTS which is 
present inside the image but Clair is showing because these vulnerabilities are present in Ubuntu 14.04 ESM and 
Clair is only referring to Ubuntu 14.04 ESM release. For example CVE-2019-1274.

\textbf{Database difference:} As we discussed earlier that Clair Scanner's database was old by one week.
                So some of the vulnerabilities were not updated yet. For example, CVE-2019-5094, which
		was published on 2019-09-24, was not 
		updated in Clair Scanner's database that time. Due to which it is missed by Clair Scanner.

\textbf{Epoch bug:} There is a bug in the Anchore scanner due to which some vulnerabilities are 
		not detected by Anchore. This bug gets triggered when a package’s version have epoch 
		(1:3.3.9-1ubuntu2.3) in it. For example, CVE-2018-1125 in Procps package is not
		detected by Anchore due to the presence of epoch in the Procps package version.

\textbf{With CVE status as "Ignored (out of standard support)" bug:} There is another bug in Anchore due to 
		which it is not able to detect some vulnerabilities. Due to this bug, Anchore does not detect 
		vulnerabilities that have a status as “ignored (out of standard support)” in Ubuntu 14.04 LTS. 
		But if this vulnerability is present in Ubuntu 14.04 ESM release it is detected by Clair. 
		For example CVE-2019-13565 in Ubuntu 14.04.


\textbf{False Negatives by Vuls:} Vuls is missing some of the vulnerabilities that it should detect. 
		For example CVE-2019-5094

\textbf{Rejected CVEs:} There are some CVE that are rejected because they are duplicate copies of other CVEs. 
	So Anchore is not reporting those rejected CVEs but Vuls is reporting those. For example CVE-2017-13753.

\subsection{Effect Of Update}
\begin{comment}
The next experiment involves updating all these images and then rescanning them to see how the number of
vulnerabilities drop inside them. We used a \textit{bash} script to update these images. This script is
present in our Github repository \href{https://github.com/kaurbhupinder/Vulnerability-Analysis}
{https://github.com/kaurbhupinder/Risk-to-Clusters-Paper}. This script 
will find the package manager inside the image and then update the image according to the package manager it finds.
\end{comment}

When the images are rescanned after the update, results changed drastically. However, there are still
vulnerabilities reported by these scanners but there are no fixes available for these vulnerabilities
to date.
\begin{comment}
There are only two
options, either you accept those vulnerabilities and use that image, or you discard that image.
So one thing is clear here that even if we keep our images up to date there will be still some
vulnerabilities that we have to face.
\end{comment}
Figure~\ref{fig:graph2} compares the number of vulnerabilities that are detected by Anchore before and after 
the update of these images.
After the update, the vulnerabilities mostly have \textit{Low, Negligible or Medium} severity status.
Also, after the update, the number of vulnerabilities have a mild slope meaning that there
are a fixed set of packages that contain vulnerabilities and have no fix yet.
\begin{figure*}[!htb]
        {\includegraphics[width=\textwidth]
        {Figures/afterupdatewithpackage.pdf}}
        \caption{\label{fig:graph2} Scatterplot representing the number of vulnerabilities before and 
	after update of the images}
      \end{figure*}
\subsection{Effect Of Size Reduction}

\bibliography{bibliography}


\end{document}

